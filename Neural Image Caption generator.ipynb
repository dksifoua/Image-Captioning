{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  2 03:23:20 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 26%   31C    P8     6W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import functools\n",
    "import collections\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "import torchvision\n",
    "from torchtext.data import Example, Field, Dataset\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of CPUs: 8\n"
     ]
    }
   ],
   "source": [
    "SEED = 781\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')\n",
    "\n",
    "N_WORKERS = multiprocessing.cpu_count()\n",
    "print(f'Number of CPUs: {N_WORKERS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 µs, sys: 24 µs, total: 65 µs\n",
      "Wall time: 71 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not os.path.exists('./data'):\n",
    "    !mkdir ./data\n",
    "    \n",
    "    !wget --no-check-certificate \\\n",
    "        https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip \\\n",
    "        -O ./data/Flickr8k_Dataset.zip\n",
    "    !unzip -q ./data/Flickr8k_Dataset.zip -d ./data\n",
    "    !rm -r ./data/Flickr8k_Dataset.zip\n",
    "\n",
    "    !wget --no-check-certificate \\\n",
    "        https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip \\\n",
    "        -O ./data/Flickr8k_text.zip\n",
    "    !unzip -q ./data/Flickr8k_text.zip -d ./data\n",
    "    !rm -r ./data/Flickr8k_text.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "\n",
    "## 3.1. Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use this corpus / data:\n",
      "\n",
      "Please cite: M. Hodosh, P. Young and J. Hockenmaier (2013) \"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics\", Journal of Artifical Intellegence Research, Volume 47, pages 853-899\n",
      "http://www.jair.org/papers/paper3994.html\n",
      "\n",
      "\n",
      "Captions, Dataset Splits, and Human Annotations :\n",
      "\n",
      "\n",
      "Flickr8k.token.txt - the raw captions of the Flickr8k Dataset . The first column is the ID of the caption which is \"image address # caption number\"\n",
      "\n",
      "Flickr8k.lemma.txt - the lemmatized version of the above captions \n",
      "\n",
      "Flickr_8k.trainImages.txt - The training images used in our experiments\n",
      "Flickr_8k.devImages.txt - The development/validation images used in our experiments\n",
      "Flickr_8k.testImages.txt - The test images used in our experiments\n",
      "\n",
      "\n",
      "ExpertAnnotations.txt is the expert judgments.  The first two columns are the image and caption IDs.  Caption IDs are <image file name>#<0-4>.  The next three columns are the expert judgments for that image-caption pair.  Scores range from 1 to 4, with a 1 indicating that the caption does not describe the image at all, a 2 indicating the caption describes minor aspects of the image but does not describe the image, a 3 indicating that the caption almost describes the image with minor mistakes, and a 4 indicating that the caption describes the image.\n",
      "\n",
      "\n",
      "CrowdFlowerAnnotations.txt contains the CrowdFlower judgments.  The first two columns are the image and caption IDs.  The third column is the percent of Yeses, the fourth column is the total number of Yeses, the fifth column is the total number of Noes.  A Yes means that the caption describes the image (possibly with minor mistakes), while a No means that the caption does not describe the image.  Each image-caption pair has a minimum of three judgments, but some may have more.\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/readme.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 8,092\n",
      "Number of train images: 6,000\n",
      "Number of valid images: 1,000\n",
      "Number of test images: 1,000\n"
     ]
    }
   ],
   "source": [
    "train_img_fn = [*map(str.strip, open('./data/Flickr_8k.trainImages.txt').readlines())]\n",
    "valid_img_fn = [*map(str.strip, open('./data/Flickr_8k.devImages.txt').readlines())]\n",
    "test_img_fn = [*map(str.strip, open('./data/Flickr_8k.testImages.txt').readlines())]\n",
    "\n",
    "img_captions = collections.defaultdict(lambda: [])\n",
    "with open('./data/Flickr8k.token.txt') as file:\n",
    "    for line in file.readlines():\n",
    "        img_fn, caption = line.strip().split('\\t')\n",
    "        img_captions[img_fn[:-2]].append(caption)\n",
    "        \n",
    "train_img_captions = dict(filter(lambda x: x[0] in train_img_fn, img_captions.items()))\n",
    "valid_img_captions = dict(filter(lambda x: x[0] in valid_img_fn, img_captions.items()))\n",
    "test_img_captions = dict(filter(lambda x: x[0] in test_img_fn, img_captions.items()))\n",
    "    \n",
    "print(f'Number of images: {len(img_captions):,}')\n",
    "print(f'Number of train images: {len(train_img_captions):,}')\n",
    "print(f'Number of valid images: {len(valid_img_captions):,}')\n",
    "print(f'Number of test images: {len(test_img_captions):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "PAD_TOKEN = '<pad>'\n",
    "SOS_TOKEN = '<sos>'\n",
    "EOS_TOKEN = '<eos>'\n",
    "UNK_TOKEN = '<unk>'\n",
    "\n",
    "def clean(caption):\n",
    "    # Remove non-alphabetical character\n",
    "    caption = re.sub(r'[^a-zA-Z]', r' ', caption)\n",
    "    # Remove one word character\n",
    "    caption = re.sub(r'\\b[a-zA-Z]\\b', r' ', caption)\n",
    "    # Remove multiple spaces\n",
    "    caption = re.sub(r'\\s+', r' ', caption)\n",
    "    return caption.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train image caption length: 33\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean captions\n",
    "train_img_captions = dict(map(lambda x: (x[0], [*map(clean, x[1])]), train_img_captions.items()))\n",
    "valid_img_captions = dict(map(lambda x: (x[0], [*map(clean, x[1])]), valid_img_captions.items()))\n",
    "test_img_captions = dict(map(lambda x: (x[0], [*map(clean, x[1])]), test_img_captions.items()))\n",
    "\n",
    "# Get the length of the longest caption\n",
    "all_train_captions = [*functools.reduce(lambda x, y: x + y, train_img_captions.values())]\n",
    "print('Max train image caption length:', max(map(len, map(str.split, all_train_captions))))\n",
    "plt.hist([*map(len, map(str.split, all_train_captions))])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:01<00:00, 21108.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary: 2,527\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 5\n",
    "MAX_LEN = 25\n",
    "all_train_captions = [*functools.reduce(lambda x, y: x + y, train_img_captions.values())]\n",
    "EN = Field(init_token=SOS_TOKEN,\n",
    "           eos_token=EOS_TOKEN,\n",
    "           fix_length=MAX_LEN,\n",
    "           lower=True,\n",
    "           tokenize='spacy',\n",
    "           tokenizer_language='en',\n",
    "           include_lengths=True)\n",
    "examples = [Example.fromlist(data=[caption], fields=[('caption', EN)])\n",
    "            for caption in tqdm.tqdm(all_train_captions)]\n",
    "captions_data = Dataset(examples, fields={'caption': EN})\n",
    "EN.build_vocab(captions_data,\n",
    "               min_freq=MIN_COUNT,\n",
    "               specials=[SOS_TOKEN, UNK_TOKEN, EOS_TOKEN, PAD_TOKEN])\n",
    "print(f'Length of vocabulary: {len(EN.vocab):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_transform(caption):\n",
    "    if isinstance(caption, str):\n",
    "        return EN.process([EN.preprocess(caption)])\n",
    "    elif isinstance(caption, list):\n",
    "        return EN.process([*map(EN.preprocess, caption)])\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (256, 256)\n",
    "\n",
    "img_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x: x / 255.),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCaptionDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data_path, img_captions, split_set, img_transform, caption_transform, img_shape=(256, 256)):\n",
    "        assert split_set in {'TRAIN', 'VALID', 'TEST'}\n",
    "        self.data_path = data_path\n",
    "        self.img_captions = img_captions\n",
    "        self.split_set = split_set\n",
    "        self.img_transform = img_transform\n",
    "        self.caption_transform = caption_transform\n",
    "        self.img_shape = img_shape\n",
    "        self.ids = list(sorted(self.img_captions.keys()))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "\n",
    "        img = Image.open(os.path.join(self.data_path, img_id)).convert('RGB')\n",
    "        img = self.img_transform(img.resize(self.img_shape))\n",
    "\n",
    "        targets = self.img_captions[img_id]\n",
    "        targets = self.caption_transform(targets)\n",
    "        \n",
    "        idx = np.random.randint(len(targets))\n",
    "        target = (targets[0][:, idx], targets[1][idx])\n",
    "        \n",
    "        if self.split_set is 'TRAIN':\n",
    "            return img, target\n",
    "        else:\n",
    "            return img, target, targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageCaptionDataset(data_path='./data/Flicker8k_Dataset/',\n",
    "                                    img_captions=train_img_captions,\n",
    "                                    split_set='TRAIN',\n",
    "                                    img_transform=img_transform,\n",
    "                                    caption_transform=caption_transform)\n",
    "valid_dataset = ImageCaptionDataset(data_path='./data/Flicker8k_Dataset/',\n",
    "                                    img_captions=valid_img_captions,\n",
    "                                    split_set='VALID',\n",
    "                                    img_transform=img_transform,\n",
    "                                    caption_transform=caption_transform)\n",
    "test_dataset = ImageCaptionDataset(data_path='./data/Flicker8k_Dataset/',\n",
    "                                   img_captions=test_img_captions,\n",
    "                                   split_set='TEST',\n",
    "                                   img_transform=img_transform,\n",
    "                                   caption_transform=caption_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "\n",
    "## 4.1. Generate image features - ResNet Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size=2048):\n",
    "        super(ResNetEncoder, self).__init__()\n",
    "        resnet = torchvision.models.resnet101(pretrained=True)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "    def fine_tuning_resnet(self, fine_tune):\n",
    "        for p in self.resnet.parameters():\n",
    "            p.requires_grad = False\n",
    "        for c in list(self.resnet.children())[5:]:\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = fine_tune\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            images: Tensor[batch_size, 3, img_size, img_size]\n",
    "        :return\n",
    "            out: Tensor[batch_size, 8, 8, hidden_size]\n",
    "        \"\"\"\n",
    "        out = self.resnet(images)\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n",
      "100%|██████████| 170M/170M [00:08<00:00, 22.2MB/s] \n"
     ]
    }
   ],
   "source": [
    "def test_encoder():\n",
    "    encoder = ResNetEncoder()\n",
    "    latent = encoder(torch.rand((10, 3, 256, 256)))\n",
    "    assert latent.size() == torch.Size([10, 8, 8, 2048])\n",
    "    \n",
    "test_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Badhanau Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_hidden_size, dec_hidden_size, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = nn.Linear(enc_hidden_size, hidden_size)\n",
    "        self.W2 = nn.Linear(dec_hidden_size, hidden_size)\n",
    "        self.V = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, features, h_state):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            features:  Tensor[batch_size, num_pixels, enc_hidden_size]\n",
    "            h_state: Tensor[batch_size, dec_hidden_size]\n",
    "        :return\n",
    "            context_vector: Tensor[batch_size, enc_hidden_size]\n",
    "            attention_weights: Tensor[batch_size, num_pixels]\n",
    "        \"\"\"\n",
    "        h_state = h_state.unsqueeze(1) # [batch_size, 1, dec_hidden_size]\n",
    "        score = torch.tanh(self.W1(features) + self.W2(h_state)) # [batch_size, num_pixels, hidden_size]\n",
    "        attention_weights = F.softmax(self.V(score), dim=1) # [batch_size, num_pixels, 1]\n",
    "        context_vector = attention_weights * features # [batch_size, num_pixels, enc_hidden_size]\n",
    "        context_vector = torch.sum(context_vector, dim=1) # [batch_size, enc_hidden_size]\n",
    "        return context_vector, attention_weights.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attention():\n",
    "    attention = BahdanauAttention(enc_hidden_size=2048, dec_hidden_size=512, hidden_size=512)\n",
    "    context_vector, attention_weights = attention(torch.rand((10, 8*8, 2048)), torch.rand((10, 512)))\n",
    "    assert context_vector.size() == torch.Size([10, 2048])\n",
    "    assert attention_weights.size() == torch.Size([10, 8*8])\n",
    "    \n",
    "test_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Generate captions - LSTM Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithBahdanauAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_hidden_size, attn_hidden_size, hidden_size, embedding_size, vocab_size, dropout):\n",
    "        super(DecoderWithBahdanauAttention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.lstm = nn.LSTM(embedding_size + enc_hidden_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(enc_hidden_size, hidden_size, attn_hidden_size)\n",
    "        self.f_beta = nn.Linear(hidden_size, enc_hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        self.embedding.weight = nn.Parameter(embeddings)\n",
    "        \n",
    "    def fine_tuning_embeddings(self, fine_tune=False):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad = fine_tune\n",
    "        \n",
    "    def forward(self, input_word_index, h_state, c_state, enc_outputs):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            input_word_index: Tensor[batch_size,]\n",
    "            h_state: Tensor[1, batch_size, hidden_size]\n",
    "            c_state: Tensor[1, batch_size, hidden_size]\n",
    "            enc_outputs: Tensor[batch_size, num_pixels, enc_hidden_size]\n",
    "        :return\n",
    "            logit: Tensor[batch_size, vocab_size]\n",
    "            h_state: Tensor[1, batch_size, hidden_size]\n",
    "            c_state: Tensor[1, batch_size, hidden_size]\n",
    "            attention_weights: Tensor[batch_size, num_pixels]\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(input_word_index)  # [batch_size, embedding_size]\n",
    "        context_vector, attention_weights = self.attention(enc_outputs, h_state.squeeze(0))\n",
    "        # context_vector: Tensor[batch_size, enc_hidden_size]\n",
    "        # attention_weights: Tensor[batch_size, num_pixels]\n",
    "        \n",
    "        gate = torch.sigmoid(self.f_beta(h_state))  # [1, batch_size, enc_hidden_size], Gating scalar\n",
    "        context_vector = gate.squeeze(0) * context_vector # [batch_size, enc_hidden_size]\n",
    "        \n",
    "        x = torch.cat((embedded, context_vector), dim=1) # [batch_size, embedding_size + enc_hidden_size]\n",
    "        output, (h_state, c_state) = self.lstm(x.unsqueeze(0), (h_state, c_state))\n",
    "        # output: [1, batch_size, hidden_size]\n",
    "        # h_state: [1, batch_size, hidden_size]\n",
    "        # c_state: [1, batch_size, hidden_size]\n",
    "        \n",
    "        logit = self.fc(self.dropout(output)) # [1, batch_size, vocab_size]\n",
    "        logit = logit.squeeze(0) # [batch_size, vocab_size]\n",
    "        return logit, h_state, c_state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_decoder():\n",
    "    decoder = DecoderWithBahdanauAttention(enc_hidden_size=2048,\n",
    "                                           attn_hidden_size=512,\n",
    "                                           hidden_size=512,\n",
    "                                           embedding_size=512,\n",
    "                                           vocab_size=1000,\n",
    "                                           dropout=0.5)\n",
    "    logit, h_state, c_state, attention_weights = decoder(torch.randint(low=0, high=1000, size=(10,)),\n",
    "                                                         torch.rand((1, 10, 512)),\n",
    "                                                         torch.rand((1, 10, 512)),\n",
    "                                                         torch.rand((10, 14*14, 2048)))\n",
    "    assert logit.size() == torch.Size([10, 1000])\n",
    "    assert h_state.size() == torch.Size([1, 10, 512])\n",
    "    assert c_state.size() == torch.Size([1, 10, 512])\n",
    "    assert attention_weights.size() == torch.Size([10, 14*14])\n",
    "    \n",
    "test_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Putting all together - AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.init_h0 = nn.Linear(encoder.hidden_size, decoder.hidden_size)\n",
    "        self.init_c0 = nn.Linear(encoder.hidden_size, decoder.hidden_size)\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, images, target_sequences, sequence_lengths, tf_ratio):\n",
    "        \"\"\"\n",
    "        :param\n",
    "            images: Tensor[batch_size, 3, img_size, img_size]\n",
    "            target_sequences: Tensor[batch_size, seq_len]\n",
    "            sequence_lengths: Tensor[batch_size,]\n",
    "            tf_ratio: float\n",
    "        :return\n",
    "            logits: Tensor[max(decode_lengths), batch_size, vocab_size]\n",
    "            logits: Tensor[batch_size, max(decode_lengths), num_pixels]\n",
    "            sorted_target_sequences: Tensor[seq_len, batch_size]\n",
    "            sorted_decode_lengths: list[seq_len]\n",
    "            sorted_indices: list[batch_size]\n",
    "        \"\"\"\n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        # Encoding\n",
    "        image_features = self.encoder(images) # [batch_size, 14, 14, hidden_size]\n",
    "        image_features = image_features.view(batch_size, -1, self.encoder.hidden_size) # [batch_size, num_pixels, enc_hidden_size]\n",
    "        num_pixels = image_features.size(1)\n",
    "        \n",
    "        # Sort the batch by decreasing lengths\n",
    "        sorted_sequence_lengths, sorted_indices = torch.sort(sequence_lengths, dim=0, descending=True)\n",
    "        sorted_image_features = image_features[sorted_indices] # [batch_size, num_pixels, enc_hidden_size]\n",
    "        sorted_target_sequences = target_sequences[sorted_indices] # [seq_len, batch_size]\n",
    "        \n",
    "        # Init hidden and memory states\n",
    "        mean_image_features = sorted_image_features.mean(dim=1) # [batch_size, enc_hidden_size]\n",
    "        h_state, c_state = self.init_h0(mean_image_features), self.init_c0(mean_image_features) # [batch_size, dec_hidden_size]\n",
    "        h_state, c_state = h_state.unsqueeze(0), c_state.unsqueeze(0) # [1, batch_size, dec_hidden_size]\n",
    "        \n",
    "        # We won't decode at the <eos> position, since we've finished generating as soon as we generate <eos>\n",
    "        # So, decoding lengths are actual lengths - 1\n",
    "        sorted_decode_lengths = (sorted_sequence_lengths - 1).tolist()\n",
    "        \n",
    "        # Decoding\n",
    "        logits = torch.zeros(max(sorted_decode_lengths), batch_size, self.decoder.vocab_size).to(self.device)\n",
    "        alphas = torch.zeros(batch_size, max(sorted_decode_lengths), num_pixels).to(self.device)\n",
    "        last = None\n",
    "        for t in range(max(sorted_decode_lengths)):\n",
    "            batch_size_t = sum([l > t for l in sorted_decode_lengths])\n",
    "            \n",
    "            if last is not None:\n",
    "                if random.random() < tf_ratio:\n",
    "                    in_ = last[:batch_size_t]\n",
    "                else:\n",
    "                    in_ = sorted_target_sequences[:batch_size_t, t]\n",
    "            else:\n",
    "                in_ = sorted_target_sequences[:batch_size_t, t]\n",
    "            \n",
    "            logit, h_state, c_state, attention_weights = self.decoder(in_,\n",
    "                                                                      h_state[:, :batch_size_t, :],\n",
    "                                                                      c_state[:, :batch_size_t, :],\n",
    "                                                                      sorted_image_features[:batch_size_t, :, :])\n",
    "            logits[t, :batch_size_t, :] = logit\n",
    "            alphas[:batch_size_t, t, :] = attention_weights\n",
    "            last = torch.argmax(F.softmax(logit, dim=1), dim=1) # [batch_size,]\n",
    "        \n",
    "        return logits, alphas, sorted_target_sequences, sorted_decode_lengths, sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_autoencoder():\n",
    "    encoder = ResNetEncoder()\n",
    "    decoder = DecoderWithBahdanauAttention(enc_hidden_size=2048,\n",
    "                                           attn_hidden_size=512,\n",
    "                                           hidden_size=512,\n",
    "                                           embedding_size=512,\n",
    "                                           vocab_size=1000,\n",
    "                                           dropout=0.5)\n",
    "    autoencoder = AutoEncoder(encoder=encoder, decoder=decoder, device='cpu')\n",
    "    logits, alphas, sorted_target_sequences, sorted_decode_lengths, sorted_indices = \\\n",
    "        autoencoder(torch.rand((10, 3, 256, 256)),\n",
    "                    torch.randint(low=0, high=1000, size=(10, 25)),\n",
    "                    torch.randint(low=5, high=26, size=(10,)), 0.5)\n",
    "    assert logits.size() == torch.Size([max(sorted_decode_lengths), 10, 1000])\n",
    "    assert alphas.size() == torch.Size([10, max(sorted_decode_lengths), 8*8])\n",
    "    assert len(sorted_decode_lengths) == 10\n",
    "    assert sorted_target_sequences.size() == torch.Size([10, 25])\n",
    "    assert len(sorted_indices) == 10\n",
    "    \n",
    "test_autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training\n",
    "\n",
    "## 5.1. Training routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def init_embeddings(embeddings):\n",
    "    bias = np.sqrt(3.0 / embeddings.size(1))\n",
    "    torch.nn.init.uniform_(embeddings, -bias, bias)\n",
    "\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
    "\n",
    "def save_checkpoint(model, optimizer, data_name, epoch, last_improv, bleu4, is_best):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'bleu-4': bleu4,\n",
    "        'last_improv': last_improv,\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    if not os.path.exists('./checkpoint'):\n",
    "        !mkdir ./checkpoint\n",
    "    torch.save(state, './checkpoint/' + data_name + '.pt')\n",
    "    if is_best:\n",
    "        torch.save(state, './checkpoint/' + 'BEST_' + data_name + '.pt')\n",
    "\n",
    "        \n",
    "class AvgMeter(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def adjust_lr(optimizer, shrink_factor):\n",
    "    print(\"\\nDecaying learning rate.\")\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
    "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))\n",
    "    \n",
    "def accuracy(outputs, target_sequences, k=5):\n",
    "    batch_size = outputs.size(1)\n",
    "    _, indices = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
    "    correct = indices.eq(target_sequences.view(-1, 1).expand_as(indices))\n",
    "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
    "    return correct_total.item() * (100.0 / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, criterion, loader, epoch, grad_clip, alpha_c, tf_ratio, device):\n",
    "    loss_tracker, acc_tracker = AvgMeter(), AvgMeter()\n",
    "    model.train()\n",
    "    pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "    for i, (images, (target_sequences, sequence_lengths)) in pbar:\n",
    "        images = images.to(device)\n",
    "        target_sequences = target_sequences.to(device)\n",
    "        sequence_lengths = sequence_lengths.to(device)\n",
    "        # Forward prop.\n",
    "        logits, alphas, sorted_target_sequences, sorted_decode_lengths, sorted_indices = model(images, target_sequences, sequence_lengths, tf_ratio)\n",
    "        # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "        sorted_target_sequences = sorted_target_sequences[:, 1:]\n",
    "        # Remove paddings\n",
    "        logits = pack_padded_sequence(logits, sorted_decode_lengths).data\n",
    "        sorted_target_sequences = pack_padded_sequence(sorted_target_sequences, sorted_decode_lengths, batch_first=True).data\n",
    "        # Calculate loss\n",
    "        loss = criterion(logits, sorted_target_sequences)\n",
    "        # Add doubly stochastic attention regularization\n",
    "        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "        # Back prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(optimizer, grad_clip)\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Track metrics\n",
    "        loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "        acc_tracker.update(accuracy(logits, sorted_target_sequences, 5), sum(sorted_decode_lengths))\n",
    "        # Update progressbar description\n",
    "        pbar.set_description(f'Epoch: {epoch + 1:03d} - loss: {loss_tracker.avg:.3f} - acc: {acc_tracker.avg:.3f}%')\n",
    "    return loss_tracker.avg, acc_tracker.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, loader, field, epoch, alpha_c, device):\n",
    "    references, hypotheses = [], []\n",
    "    loss_tracker, acc_tracker = AvgMeter(), AvgMeter()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
    "        for i, (images, (target_sequences, sequence_lengths), (all_target_sequences, all_sequence_lengths)) in pbar:\n",
    "            images = images.to(device)\n",
    "            target_sequences = target_sequences.to(device)\n",
    "            sequence_lengths = sequence_lengths.to(device)\n",
    "            all_target_sequences = all_target_sequences.to(device)\n",
    "            all_sequence_lengths = all_sequence_lengths.to(device)\n",
    "            # Forward prop.\n",
    "            logits, alphas, sorted_target_sequences, sorted_decode_lengths, sorted_indices = model(images, target_sequences, sequence_lengths, 0)\n",
    "            # Since we decoded starting with <sos>, the targets are all words after <sos>, up to <eos>\n",
    "            sorted_target_sequences = sorted_target_sequences[:, 1:]\n",
    "            # Remove paddings\n",
    "            logits_copy = logits.clone()\n",
    "            logits = pack_padded_sequence(logits, sorted_decode_lengths).data\n",
    "            sorted_target_sequences = pack_padded_sequence(sorted_target_sequences, sorted_decode_lengths, batch_first=True).data\n",
    "            # Calculate loss\n",
    "            loss = criterion(logits, sorted_target_sequences)\n",
    "            # Add doubly stochastic attention regularization\n",
    "            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n",
    "            # Track metrics\n",
    "            loss_tracker.update(loss.item(), sum(sorted_decode_lengths))\n",
    "            acc_tracker.update(accuracy(logits, sorted_target_sequences, 5), sum(sorted_decode_lengths))\n",
    "            # Update references\n",
    "            all_sorted_target_sequences = all_target_sequences[sorted_indices] # Because images were sorted in the decoder\n",
    "            for j in range(all_sorted_target_sequences.size(0)):\n",
    "                img_caps = all_sorted_target_sequences[j].t().tolist()\n",
    "                # Remove <sos> and <pad> tokens\n",
    "                img_caps = [*map(lambda c: [field.vocab.itos[w] for w in c\n",
    "                                            if w not in (field.vocab.stoi[field.init_token],\n",
    "                                                         field.vocab.stoi[field.pad_token])], img_caps)]\n",
    "                references.append(img_caps)\n",
    "            # Update hypotheses\n",
    "            _, preds = torch.max(logits_copy, dim=2)\n",
    "            preds, temp_preds = preds.t().tolist(), []\n",
    "            for j, p in enumerate(preds):\n",
    "                temp_preds.append([*map(lambda w: field.vocab.itos[w], preds[j][:sorted_decode_lengths[j]])]) # Remove padding\n",
    "            hypotheses.extend(temp_preds)\n",
    "            # Update progressbar description\n",
    "            pbar.set_description(f'Epoch: {epoch + 1:03d} - val_loss: {loss_tracker.avg:.3f} - val_acc: {acc_tracker.avg:.3f}%')\n",
    "        # Calculate BLEU-4 score\n",
    "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25])\n",
    "    return loss_tracker.avg, acc_tracker.avg, bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, valid_loader, field, alpha_c, start_epoch, n_epochs, grad_clip, tf_ratio, device, model_name, last_improv):\n",
    "    history, best_bleu = {\n",
    "        'acc': [],\n",
    "        'loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_loss': [],\n",
    "        'bleu4': []\n",
    "    }, 0.\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        # Stop training if no improvment since last 4 epochs\n",
    "        if last_improv == 4:\n",
    "            print('Training Finished - The model has stopped improving since last 4 epochs')\n",
    "            break\n",
    "        # Decay LR if no improvment\n",
    "        if last_improv > 0:\n",
    "            adjust_lr(optimizer, 0.9)\n",
    "        # Train step\n",
    "        loss, acc = train_step(model=model, optimizer=optimizer, criterion=criterion,\n",
    "                               loader=train_loader, epoch=epoch, grad_clip=grad_clip,\n",
    "                               alpha_c=alpha_c, tf_ratio=tf_ratio, device=device)\n",
    "        # Validation step\n",
    "        val_loss, val_acc, bleu4 = validate(model=model, criterion=criterion, loader=valid_loader,\n",
    "                                            field=field, epoch=epoch, alpha_c=alpha_c, device=device)\n",
    "        # Update history dict\n",
    "        history['acc'].append(acc)\n",
    "        history['loss'].append(loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['bleu4'].append(bleu4)\n",
    "        # Print BLEU score\n",
    "        text = f'BLEU-4: {bleu4*100:.3f}%'\n",
    "        if best_bleu > bleu4:\n",
    "            last_improv += 1\n",
    "            text += f' - Last improvement since {last_improv} epoch(s)'\n",
    "        else:\n",
    "            best_bleu, last_improv = bleu4, 0\n",
    "        print(text)\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(model=model, optimizer=optimizer, data_name=model_name, epoch=epoch, last_improv=last_improv, bleu4=bleu4, is_best=bleu4 >= best_bleu)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Flickr_8k'\n",
    "ENCODER_HIDDEN_SIZE = 2048\n",
    "ATTENTION_SIZE = 512\n",
    "DECODER_HIDDEN_SIZE = 512\n",
    "EMBEDDING_SIZE = 512\n",
    "DROPOUT = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "grad_clip = 5.\n",
    "alpha_c = 1.\n",
    "tf_ratio = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the model: 13,346,784\n"
     ]
    }
   ],
   "source": [
    "encoder = ResNetEncoder()\n",
    "encoder.fine_tuning_resnet(fine_tune=False)\n",
    "decoder = DecoderWithBahdanauAttention(enc_hidden_size=ENCODER_HIDDEN_SIZE,\n",
    "                                       attn_hidden_size=ATTENTION_SIZE,\n",
    "                                       hidden_size=DECODER_HIDDEN_SIZE,\n",
    "                                       embedding_size=EMBEDDING_SIZE,\n",
    "                                       vocab_size=len(EN.vocab),\n",
    "                                       dropout=DROPOUT)\n",
    "init_embeddings(decoder.embedding.weight)\n",
    "autoencoder = AutoEncoder(encoder=encoder, decoder=decoder, device=DEVICE).to(DEVICE)\n",
    "optimizer = optim.Adam(params=autoencoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(f'Number of parameters of the model: {count_parameters(autoencoder):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           num_workers=N_WORKERS,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           num_workers=N_WORKERS,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - loss: 6.126 - acc: 7.477%: 100%|██████████| 94/94 [00:40<00:00,  2.33it/s]\n",
      "Epoch: 001 - val_loss: 5.772 - val_acc: 8.412%: 100%|██████████| 16/16 [00:07<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 0.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 002 - loss: 5.411 - acc: 10.126%: 100%|██████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch: 002 - val_loss: 5.044 - val_acc: 11.503%: 100%|██████████| 16/16 [00:06<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 5.128%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 003 - loss: 4.875 - acc: 12.183%: 100%|██████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch: 003 - val_loss: 4.762 - val_acc: 12.338%: 100%|██████████| 16/16 [00:06<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 6.036%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 004 - loss: 4.629 - acc: 12.907%: 100%|██████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch: 004 - val_loss: 4.588 - val_acc: 12.780%: 100%|██████████| 16/16 [00:06<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 6.273%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 005 - loss: 4.450 - acc: 13.567%: 100%|██████████| 94/94 [00:38<00:00,  2.44it/s]\n",
      "Epoch: 005 - val_loss: 4.489 - val_acc: 13.566%: 100%|██████████| 16/16 [00:06<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 6.541%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 006 - loss: 4.314 - acc: 13.977%: 100%|██████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch: 006 - val_loss: 4.417 - val_acc: 13.758%: 100%|██████████| 16/16 [00:06<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 7.781%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 007 - loss: 4.216 - acc: 14.211%: 100%|██████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch: 007 - val_loss: 4.395 - val_acc: 13.675%: 100%|██████████| 16/16 [00:06<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 7.089% - Last improvement since 1 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 008 - loss: 4.106 - acc: 14.680%: 100%|██████████| 94/94 [00:38<00:00,  2.44it/s]\n",
      "Epoch: 008 - val_loss: 4.306 - val_acc: 14.080%: 100%|██████████| 16/16 [00:06<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 7.790%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 009 - loss: 4.016 - acc: 14.952%: 100%|██████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch: 009 - val_loss: 4.254 - val_acc: 14.498%: 100%|██████████| 16/16 [00:06<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 7.993%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 010 - loss: 3.942 - acc: 15.182%: 100%|██████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch: 010 - val_loss: 4.230 - val_acc: 14.524%: 100%|██████████| 16/16 [00:06<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 8.704%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 011 - loss: 3.863 - acc: 15.499%: 100%|██████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch: 011 - val_loss: 4.207 - val_acc: 14.692%: 100%|██████████| 16/16 [00:06<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 8.571% - Last improvement since 1 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000810\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 012 - loss: 3.793 - acc: 15.653%: 100%|██████████| 94/94 [00:38<00:00,  2.46it/s]\n",
      "Epoch: 012 - val_loss: 4.195 - val_acc: 14.771%: 100%|██████████| 16/16 [00:06<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 8.476% - Last improvement since 2 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000729\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 013 - loss: 3.708 - acc: 16.114%: 100%|██████████| 94/94 [00:38<00:00,  2.44it/s]\n",
      "Epoch: 013 - val_loss: 4.193 - val_acc: 14.408%: 100%|██████████| 16/16 [00:06<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 9.044%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 014 - loss: 3.660 - acc: 16.235%: 100%|██████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch: 014 - val_loss: 4.167 - val_acc: 14.718%: 100%|██████████| 16/16 [00:06<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 9.476%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 015 - loss: 3.597 - acc: 16.610%: 100%|██████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch: 015 - val_loss: 4.170 - val_acc: 14.779%: 100%|██████████| 16/16 [00:06<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 9.181% - Last improvement since 1 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000656\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 016 - loss: 3.547 - acc: 16.857%: 100%|██████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch: 016 - val_loss: 4.159 - val_acc: 14.803%: 100%|██████████| 16/16 [00:06<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 9.279% - Last improvement since 2 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000590\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 017 - loss: 3.488 - acc: 16.910%: 100%|██████████| 94/94 [00:38<00:00,  2.45it/s]\n",
      "Epoch: 017 - val_loss: 4.172 - val_acc: 14.824%: 100%|██████████| 16/16 [00:06<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 9.221% - Last improvement since 3 epoch(s)\n",
      "\n",
      "Decaying learning rate.\n",
      "The new learning rate is 0.000531\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 018 - loss: 3.428 - acc: 17.278%: 100%|██████████| 94/94 [00:38<00:00,  2.43it/s]\n",
      "Epoch: 018 - val_loss: 4.145 - val_acc: 15.022%: 100%|██████████| 16/16 [00:06<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-4: 8.874% - Last improvement since 4 epoch(s)\n",
      "Training Finished - The model has stopped improving since last 4 epochs\n"
     ]
    }
   ],
   "source": [
    "history = train(model=autoencoder,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                train_loader=train_loader,\n",
    "                valid_loader=valid_loader,\n",
    "                field=EN,\n",
    "                alpha_c=alpha_c,\n",
    "                start_epoch=0,\n",
    "                n_epochs=n_epochs,\n",
    "                grad_clip=grad_clip,\n",
    "                tf_ratio=tf_ratio,\n",
    "                device=DEVICE,\n",
    "                model_name=MODEL_NAME,\n",
    "                last_improv=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAFNCAYAAAAkWSjbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeXxU1fn48c+TyR5CVhICgYQdhLCGHTQgIiDudbdWa12+X1u7fG2r7a+t3e3it9XaarWu3yK4FVeQTQJuLKJAkJ0QICEh+55JJpPz++NOMDvbTGbCPO/Xa15zc8+59z6T1puHM889R4wxKKWUUkoppc5NgLcDUEoppZRS6nygibVSSimllFJuoIm1UkoppZRSbqCJtVJKKaWUUm6gibVSSimllFJuoIm1UkoppZRSbqCJtfJbInK7iHzURftKEflGd8aklFLK/UTEiMjQTtpuEZHV3R2TOj9pYq28TkRyRGSet+Noyxiz0Bjz4qn6dXXDVkopXycimSJSJiIh3o7FG4wxS4wx80/VT0ReEJHfdEdMqufSxFopLxKRQG/HoJTyXyKSCswGDHBFN1/br+5/ImLzdgzK8zSxVj5NRO4SkYMiUioib4tIP9d+EZG/iEihiFSKSJaIjHG1LRKR3SJSJSJ5IvLAKa7xZ9dozWERWdhif6aIfMu1PVRENohIhYgUi8grrv0bXd13iEi1iNzQVdyuNiMi94nIAeCAiPxdRB5tE9PbIvL9c/8NKqVUl24DNgEvAK1K30QkTEQeFZEjrnvfRyIS5mqbJSKfiEi5iBwTkdtd+0/eN10/tyq5a3v/c+17zHWOShHZJiKzW/S3ichPROSQ656+TUQGnOV9c56IHHDF/HcRkbYxdva3RUTuBm4BfuS617/j6j/K9ZnLReRLETn5jxPXCPeTIrJCRGqAH4jIiZYJtohcIyI7Tv0/k+opNLFWPktE5gK/B64HkoAjwDJX83zgQmA4EOXqU+Jqexa4xxgTCYwBPujiMlOBfUA88Efg2eabbRu/BlYDMUAy8DcAY8yFrvZxxphexphXThF3s6tc174AeBG4SUQCXJ87HpgHvNxF3Eop5Q63AUtcr0tFJLFF25+BScAMIBb4EdAkIinASqz7YB9gPLD9DK7Z8v4HsNV1jlis+95rIhLqavsBcBOwCOgNfBOo5ezum4uBycBYrPvzpR306fBvizHmaazf0R9d9/rLRSQIeAfrb0MC8B1giYiMaHG+m4HfApFYv68S1zWafR14qYuYVQ+jibXyZbcAzxljPjfG1AMPAdNdX106sG5UIwExxuwxxuS7jnMAF4hIb2NMmTHm8y6uccQY84wxxol1o04CEjvo5wBSgH7GGLsxptOHHk8Rd7PfG2NKjTF1xpgtQAVwsavtRiDTGHOii2sopdQ5EZFZWPe1V40x24BDWIkgroT1m8B3jTF5xhinMeYT1z3tZmCtMWapMcZhjCkxxpxJYn3y/gdgjPm36xyNxphHgRCgOTn9FvD/jDH7jGWHq+/Z3DcfMcaUG2OOAuuxkvm2uvrb0tY0oJfrvA3GmA+Ad7H+IdDsLWPMx8aYJmOMHevvzK0AIhKLldzrIMp5RBNr5cv6YY32AmCMqcb6135/1w3sCeDvQKGIPC0ivV1dr8Ua3TjiKt+Y3sU1Clqcv9a12auDfj8CBNji+rrvm2cTd4s+x9occ/Jm63r/vy7Or5RS7vANYLUxptj188t8VQ4SD4RiJdttDehk/+lqdf8TkQdEZI+r3KQca6Q4/jSudab3zYIW27V0cK8/xd+WtvoBx4wxTS32HaHre/2/gctFJAJrNPzDLhJ31QNpYq182XGs0RQAXDeiOCAPwBjzuDFmEtbXicOBH7r2bzXGXIn11dybwKvnGogxpsAYc5cxph9wD/AP6XwmkC7jbj5lm2P+DVwpIuOAUa64lVLKI1y10tcDF4lIgYgUAN8HxrnuQ8WAHRjSweHHOtkPUAOEt/i5bwd9Tt7/XPXUP3LFEmOMicYaiW4uyevqWh65b3b2t4X29+3jwIDmchSXgXRxrzfG5AGfAtdglYHoIMp5RhNr5SuCRCS0xSsQWArcISLjxZoG6nfAZmNMjohMFpGprhq3Gqw/AE0iEizWnKRRxhgHUAk0dXrV0yQi14lIsuvHMqybZfN5TwCDW3TvNO7Ozm+MycWqM/w/4I3mr0iVUspDrgKcWMnjeNdrFPAhcJtrFPY54H9FpJ/rIcLprnvaEqwHAa8XkUARiROR5rKK7cA1IhLuGny48xRxRAKNQBEQKCI/x6qlbvYv4NciMsz1YOFYEYkDz9w3O/vb4mpue6/fjDXy/SMRCRKRDOBy2j9T09ZLWP+YSAP+c64xK9+iibXyFSuAuhavh40xa4GfAW8A+VijFje6+vcGnsFKco9glVr8ydX2dSBHRCqBe7Fqns/VZGCziFQDb2PVHWa72h4GXnQ9FX79KeLuyotYN1odwVBKedo3gOeNMUdd38gVGGMKsMogbnENbjwAZGElr6XAH4AAV43yIuB/XPu3A+Nc5/0L0ICVhL6IlYR3ZRXwPrAf615up3X5xP9ifeu4Gmug5FkgrEW7u++bXf1teRbr+Z1yEXnTGNOAlUgvxBrh/wfWP0r2nuIay7G+1VzeogRRnSfEmLbfbCilvEFELsT6ajPF6H+YSil1Sj31vikih7Bmr1rr7ViUe+mItVI+wPW143eBf/WkPw5KKeUtPfW+KSLXYpUTdjUVrOqhNLFWystEZBRQjjXV31+9HI5SSvm8nnrfFJFM4EngvjaziajzhJaCKKWUUkop5QY6Yq2UUkoppZQbaGKtlFJKKaWUGwR6O4AzFR8fb1JTU8/4uJqaGiIiItwfkBv5eoy+Hh9ojO7g6/FBz45x27ZtxcaYPl4IySv0nu1dvh6jr8cHGqM7+Hp84MZ7tjGmR70mTZpkzsb69evP6rju5Osx+np8xmiM7uDr8RnTs2MEPjM+cC/trpfes73L12P09fiM0RjdwdfjM8Z992wtBVFKKaWUUsoNNLFWSimllFLKDTSxVkoppZRSyg163MOLSimlzp6IPAcsBgqNMWNc+14BRri6RAPlxpjxHRybA1QBTqDRGJN+NjE4HA5yc3Ox2+2d9omKimLPnj1nc/pu44kYQ0NDSU5OJigoyK3nVUp1D02slVLKv7wAPAG81LzDGHND87aIPApUdHH8HGNM8bkEkJubS2RkJKmpqYhIh32qqqqIjIw8l8t4nLtjNMZQUlJCbm4ugwYNctt5lVLdR0tBlFLKjxhjNgKlHbWJleVeDyz1ZAx2u524uLhOk2p/JSLExcV1OZKvlPJtmlgrpZRqNhs4YYw50Em7AVaLyDYRuftcLqRJdcf096JUz6alIEoppZrdRNej1bOMMXkikgCsEZG9rhHwVlxJ990AiYmJZGZmtmqPioqiqqqqy0CcTucp+5yL8vJyXnvtNe66664zOu7aa6/l2WefJTo62mMx2u32dr+zs1VdXe22c3mCr8cHGqM7+Hp84L4YNbFWSimFiAQC1wCTOutjjMlzvReKyHJgCtAusTbGPA08DZCenm4yMjJate/Zs+eUtcmerrEuKSnhueee4wc/+EGr/Y2NjQQGdv6ncfXq1R6PMTQ0lAkTJrjlXJmZmbT9/fsSX48PNEZ38PX4wH0x+kUpyMcHi/msoNHbYSillC+bB+w1xuR21CgiESIS2bwNzAd2dWN8bvXggw9y6NAhxo8fz+TJk5k9ezZXXHEFF1xwAQBXXXUVkyZNYvTo0Tz99NMnj0tNTaW4uJicnBzS09O56667GD16NPPnz6eurs5bH0cp1YmGxibW7ytk/d7CbrmeX4xY/+vDbPbkNvCAtwNRSikvE5GlQAYQLyK5wC+MMc8CN9KmDERE+gH/MsYsAhKB5a4a4EDgZWPM+90Zuzs98sgj7Nq1i+3bt5OZmclll13Grl27Ts7G8dxzzxEbG0tdXR2TJ0/m2muvJS4urtU5Dh06xCuvvMIzzzzD9ddfzxtvvMGtt97qjY+jlGqhrsHJhv1FvL8rn3V7Cqmqb2RKaixzRiZ4/Np+kVhPGxzH+n1FFFbZSYgM9XY4SinlNcaYmzrZf3sH+44Di1zb2cA4d8fzy3e+ZPfxynb7nU4nNpvtrM55Qb/e/OLy0Wd0zJQpU1pNcff444+zfPlyAI4dO8aBAwfaJdYpKSmMH29N9z1p0iRycnLOKl6l1Lmrsjv4YG8hq74sYP3eIuocTqLDg1gwpi8L0/oyc2h8t8ThN4k1wObsUi4f18/L0SillPI1ERERJ7czMzNZu3Ytn376KeHh4WRkZHQ4BV5ISMjJbZvNpqUgSnWz8toG1uw+wfu7CvjwQDENzib6RIZw7aT+LByTxNRBsQTaurfq2S8S69H9ehNqg03ZJZpYK6WUD+lsZNnTDy9GRkZ2OqNHRUUFMTExhIeHs3fvXjZt2uSxOJRSZ6awys7qL61k+tPsEpxNhv7RYdw6LYWFaX2ZODAGW4D3pq30i8Q60BbA8Bgbmw93uCaCUkopPxMXF8fMmTMZM2YMYWFhJCYmnmxbsGABTz31FKNGjWLEiBFMmzbNi5Eq5Z+MMdQ3NlHb4KSstoEN+4p4f1cBW4+UYgykxoVz1+zBLBzTl7HJUT4zB7xfJNYAI2MDeHV/NUVV9fSJDDn1AUoppc5rL7/8cof7Q0JCWLlyZYdtzXXU8fHxbN68+eT+Bx7Qx+OVaquhsYm9BZV8mOsg+6PD1DY0UtvgpLbBSU29tV1zcl8jtfWun13vTab1+UYkRnL/3GEsTOvLiMRIn0mmW/KbxHpErA1wsPlwCYvHajmIUkoppZS7GGM4XmHni6NlbD9azhfHytmVV0F9Y5PVYdduAAIDhPBgGxEhga3eEyJDCY+zEREcSHiIjfBgG+HBgUQE2wgPCSQ9JYbBfXp58ROeHr9JrFN6BxARbGNzdqkm1koppZRS56CmvpGduRV8ceyrRLqoqh6AkMAAxvSP4uvTUhg/MJqaY3u5dM4swoMDCQ48v5dQ8WhiLSLRwL+AMYABvmmM+bRFuwCPYU3nVAvcboz53BOxBAYI6amxbMou8cTplVJKKaXOS01NhkNF1XzhSqC/OFrG/hNVJ0s1BsVHMGtoPBMGRjN+QDQj+/ZulUBnlu4nOjzYS9F3L0+PWD8GvG+M+ZqIBAPhbdoXAsNcr6nAk653j5g6OJY/vr+P4up64ntpnbVSSimlVEea54VekZXPJwdLqKq3VrDuHRrI+IExzB/d10qkk6OJifCPpPl0eCyxFpEo4ELgdgBjTAPQ0KbblcBLxhgDbBKRaBFJMsbkeyKm5vmstxwuZVFakicuoZRSSinVI1XaHazdfYIVWQVsPFBEQ2MTib1DWDyuH5NSYpgwMJpBcREEeHE6O1/nyRHrQUAR8LyIjAO2Ad81xtS06NMfONbi51zXPo8k1mn9owgPtrEpu0QTa6WUUkr5vYpaB6t3F7ByVwEfHijC4TQkRYVy69QULhvblwkDYjSRPgOeTKwDgYnAd4wxm0XkMeBB4GdneiIRuRu4GyAxMZHMzMwzDqa6upqPP9zI4EhYl3WUuVHFZ3wOT6uurj6rz9ZdfD0+0BjdwdfjA41Rdb9evXpRXV3N8ePHuf/++3n99dfb9cnIyODPf/4z6enpXohQqdNXVtPA6t0FrMgq4OODxTS6Flm5fUYqi9KSGJccrcn0WfJkYp0L5Bpjmif6fB0rsW4pDxjQ4udk175WjDFPA08DpKenm4yMjDMOJjMzk4yMDL40B/nTqn2kpU8nzsfqrJtj9FW+Hh9ojO7g6/GBxqi8p1+/fh0m1Ur5upLqelZ9eYKVu/L55JC1YuHA2HDunD2Iy9KSSOvvO4us9GQeS6yNMQUickxERhhj9gEXA7vbdHsb+LaILMN6aLHCU/XVzVrWWS/UchCllPJLDz74IAMGDOC+++4D4OGHHyYwMJD169dTVlaGw+HgN7/5DVdeeWWr43Jycli8eDG7du2irq6Ou+66ix07djBy5Ejq6uq88VGUasXucHKi0k5BhZ2CSjvHy+18eKCITdklNLlWLLznwsEsSktidL/emky7madnBfkOsMQ1I0g2cIeI3AtgjHkKWIE11d5BrOn27vBwPIxNjiIsyKqz1sRaKaX80w033MD3vve9k4n1q6++yqpVq7j//vvp3bs3xcXFTJs2jSuuuKLTxOPZZ58lPDycPXv2sHPnTiZOnNidH0H5GWMMFXUOCpqTZlfifKLSzpeH7TyyfSMnKu2U1TraHTu4TwT3zRnKwjFJjEryzRULzxceTayNMduBtsVmT7VoN8B9noyhrSBbAOmpMWw+XNqdl1VKKdWRlQ9CQVa73WHORrCd5Z+ovmmw8JEuu0yYMIHCwkKOHz9OUVERMTEx9O3bl+9///ts3LiRgIAA8vLyOHHiBH379u3wHB9//DE/+MEPABg7dixjx449u3iV6oDd4eTdnfm8tT2PY6W1FFTasTua2vWL7xVCRIBhWP8wJqXEkBQVSmLvUPpGhZ7cjgwN8sIn8E9+s/JiS9MGx/GnVfsorWkgVudeVEopv3Tdddfx+uuvU1BQwA033MCSJUsoKipi27ZtBAUFkZqait1u93aYys8cLKxiyeajvLEtl0p7I4PiIxjTP4p5oxLpG9U6YU6IDCU4MMD1TMdkb4eu8NPEeuqgWAC2HC5hwRgtB1FKKa/pZGS5rqqKyMhIj176hhtu4K677qK4uJgNGzbw6quvkpCQQFBQEOvXr+fIkSNdHj9z5kxefvll5s6dy65du9i5c6dH41Xnr/pGJ+/vKmDJ5qNsOVxKkE1YMCaJW6YOZOqgWC3d6EH8MrEemxxNaFAAm7JLNbFWSik/NXr0aKqqqujfvz9JSUnccsstXH755aSlpZGens7IkSO7PP7OO+/k/vvvZ9SoUYwaNYpJkyZ1U+TqfJFTXMPSLUd5bVsupTUNDIwN58GFI/napGRdIbqH8svEOjgwgPSUWDZll3g7FKWUUl6UlfVVfXd8fDyffvpph/2qq6sBSE1NZdeuXQCEhYWxbNkyzwepzisOZxPr9pxgyeajfHigGFuAcMmoRG6eOpBZQ+N1/ugezi8Ta7DKQR5ds5+ymgZd414ppZRSHpVXXseyLUdZtvUYRVX19IsK5QeXDOeGyQNI7B3q7fCUm/htYj1tSBysgS05pVw6uuMnvpVSSimlzlal3cGW7FJe3nKUzH2FGGDOiARumTqQjBEJ2HR0+rzjt4n12OQoV511iSbWSimllDpjTU2GE1V2jpTUcrS0lqMltRwpbd6uOTmndJ/IEO6bM5QbJg8gOSbcy1ErT/LbxDok0MbEgTFsytb5rJVSSinVsQan4WBhFUdKar9KoEtrOVJSw7GyOhoav5pb2hYg9IsOZWBsOAvGJJESF87wxF7MHtaHIFuAFz+F6i5+m1iDNZ/1X9bup7y2gehwrbNWSiml/J3d4WRTdgkb9xez8UARBwtrYc3Gk+3hwTYGxoYzNKEXF49KZEBsOCmx4aTEhdMvOkwTaD/n94m1MbDlcCnztRxEKaWU8jvGGA4UVrNxfxEb9hex+XApDY1NBAcGMHVQLGN615MxabSVQMeFExcRrPNKq075dWI9bkAUIYHWfNaaWCullP+w2WykpaVhjMFms/HEE08wY8YMcnJyWLx48ckp9ZrdfvvtbNiwgaioKADCw8NZtWoVDz/8ML169eKBBx442Tc1NZXPPvuM+Pj4Dq+9detWpk+fzrJly/ja177muQ+pOlVR6+Cjg8Vs3F/ExgNF5FdYK2wOTejFrVNTuHB4PFMHxREWbLNWNZzQ38sRq57CrxPr5jrrzYd1PmullPInYWFhbN++HYBVq1bx0EMPsWHDhi6P+dOf/tQqEa6qqjrj6zqdTn784x8zf/78Mz5WnT1nk2FHbrmVSO8vYvuxcpoMRIYGMmtoPPdf3IcLh/ehf3SYt0NVPZxfJ9ZglYP8dd1+KmodRIUHeTscpZTyKBF5DlgMFBpjxrj2PQzcBRS5uv3EGLOig2MXAI8BNuBfxpiO1yPvYSorK4mJiemWa/3tb3/j2muvZevWrd1yPX/lcDax/0QVO3Mr+OhgMR8dKKaizoGItfryt+cO46Lh8YxLjiZQa6KVG/l9Yj11cCxmrTWf9SUXJHo7HKWU8rQXgCeAl9rs/4sx5s+dHSQiNuDvwCVALrBVRN42xuz2VKCeVFdXx/jx47Hb7eTn5/PBBx+c8pgf/vCH/OY3vwGs5dCfeuqpM7pmXl4ey5cvZ/369ZpYu1Gjs4mDRdXszK0gK7eCrLwKdudXnpytI7F3CPMvSOTC4X2YNTReF4VTHuU3iXWA097h/vEDogkODGBzdokm1kqp854xZqOIpJ7FoVOAg8aYbAARWQZcCZxTYv2HLX9gb+nedvudTic2m+2szjkydiQ/nvLjLvu0LAX59NNPue2229rVVbfVUSlIZw+xdbT/e9/7Hn/4wx8ICNAR0rPlbDIcKqo+mUDvzC1nd34ldoeVRPcKCWRM/97cPiOVMf2jSOsfRWpcuD5s6O9qS6G+CmJSPH4p/0isl1xPWtFxuHhBu6bQIBsTB0azSeuslVL+7dsichvwGfA/xpiyNu39gWMtfs4FpnZXcJ40ffp0iouLKSoqOnXnNuLi4sjPz2+1r6qqiujoaP7+97/zzDPPALBixQo+++wzbrzxRgCKi4tZsWIFgYGBXHXVVef+Ic5DxhgOFdWQlVdOVm4lWXnlfHm8ktoGJ2BNezemXxS3TE1hbHJzEh1BgK5m6L8aaqF4H5zYDYXNrz1QlQ/DLoVbXvV4CP6RWMcOpveh9dDYAIHtvwKaOiiOxz84QEWdg6gwrbNWSvmdJ4FfA8b1/ijwzbM9mYjcDdwNkJiYSGZmZqv2qKiokw/+/feo/+7wHOcyYg2n92Bhc5/9+/fT2NhIcHAwhYWFNDU1tTve4XBQV1fXar/T6WTSpEl861vf4r777iMyMpK3336bMWPGUFtby2233cZtt912sv/OnTtPbt97770sWLCAiy++uN217HZ7u9/Z2aqurnbbuTyhZXzOJsORqib2lzaxr8zJgTIn1dbChQQHwMDeAcxMCiC1dzCDomz0jRACpB4ohPJCjpbDUQ/H6Kt8PUZ3xydNTsLq8omoOeJ6HSWi5ghhdfkIBoAmCaImYgA1ESOo6TOfyojhVHQRg7ti9I/EOnUmts1PwvHPYeC0ds3TBsfx2LoDfJZTysWjtBxEKeVfjDEnmrdF5Bng3Q665QEDWvyc7NrX0fmeBp4GSE9PNxkZGa3a9+zZQ2RkZJcxVVVVnbLPuairq2P27NmANTL60ksvER0dTXl5OQcOHGDUqFEn+/7lL38hKCiIn//85zz66KMn969bt47p06dz//33s3DhQkSEhIQEnn/++VPGHhQURFhYWIf9QkNDmTBhgls+Z2ZmJm1//77C7nDy/NuZOML6szWnlG1Hyk6ORqfEhbNgbCyTU2MYPyCGIX0ivPaQoS//Dpv5eoyZ69eTMWsGNDnA6YAmZ4tt18/N285GaGps0d4IjfVQeuirkeiifeCst04uARA7GFInQcJoSBgFiaMJiBlEpC2Q072LuOt36B+J9cAZ1vuRjztMrCcMtOqsN2WXaGKtlPI7IpJkjGmuZ7ga6KjYeCswTEQGYSXUNwI3d1OIbud0Ojvcn5qaisPhaLf/uuuua7eveaT5nnvu4Z577jmj67/wwgtn1P98UFHnYNuRUrYcLmNrTik7c8txOA0i+xmRGMnXJiUzZVAsk1NjSewd6u1wT5+zEewVUFcG9nLrva4M6lzbIjB0HvSbYG17mzHQaLdqjuuroL7S9V7d5ucqaHDta6ixElxnw1fJ7hlsZxgndD2b5emJTIKEC2DQhZA42truMwKCfGeaRP9IrCPiqAkfSETOxzD7f9o1hwbZGD8gmk3ZpV4ITimluo+ILAUygHgRyQV+AWSIyHisUpAc4B5X335Y0+otMsY0isi3gVVY0+09Z4z50gsfQfUQlXYHG/cXsfVwKVtyythbUIkxEGQT0vpH8c1ZgwiryuOOxRf53nS39kprhLTkEAOOfghrN3yVMLdKniugvuIUJxNY/1vonQyjFsOoy2HgdAg4+1KnUzLGqi0+9AEc3gAVeV8lzQ3VVtJ7KmKDkEgI6W0lrrZgsAVZr4AgCO711XbL/c3btmAICARbEDlH80gdMvSr9oDAk20EuH62BbZot7XuawuC6BQIj/Xc78xN/COxBsqjRxNx7EPrX5a29h972uA4nvjgAJV2B71Dfew/cKWUchNjzE0d7H62k77HgUUtfl4BtJvfWqmWduVV8O9NR3hr+3HqHE7Cg63F2L538XAmD4phwoAYwoKtpDIz84T3kurGeig9DCUHW7wOWe81hSe7DQHICYSwGAiNtt579YU+I63tlvtPvlw/h0ZZCe3+92HPO/DZ87D5KQiPgxGLrCR7cAYEhpz756kuhOxMK5k+tB6qC6z9ccOsUd2QyNav4F5W0tx2f/MrMNRtI+w5mZmkXpjhlnP5Or9KrPsfXwkFO6D/pHbt0wbH8vg6+CynlLkjtRxEKaWUOl12h5N3d+bz701H2H6snNCgAK4c15/rJyczNjmaIG8twtLkhIrc1klz86viGJimr/pGJEDcUBg+33p3vT7ceZjZFy88+yQzPBbG32y96qvh4Foryd79FnzxfxAcCcMusZLsYZdYSe3pcNTB0U/h0Aek73gXMg9b+8NirWR9yFwYMgeiks8ubnVW/CaxrogabW0c+aTDxHriwBiCbQFsytbEWimlPM0Yo3MLd8AY4+0QzkhOcQ1LNh/htW25lNc6GNwngp8vvoBrJyWf2yxbDjvsWwEH1nxVuuBscL1abHe4v/khuIb2JQ/BkRA3BJInw7ibXMnzEOsVGtVhKM7AE+6rjQ7pBaOvsl6N9XB4o5Vk730PvvwP2EKsZHjkYmtEOyLuq2ONgRO7rNHoQx9YSXWjHQKCcPQeCRf/wjq27zjQudK9xm8S64aQWIgdAjkfw4zvtGtvrrPenK3zWSullCeFhv1jXGMAACAASURBVIZSUlJCXFycJtctGGMoKSkhNNS3H9xrdDaxbm8h/950hA8PFBMYIMwfncitU1OYPuQc/jc1Bo5ugh1L4cs3rdrl8HiIiG9Rs+uquw2KctX8Brrem+t5g9vvj0z6agS6V4JvPEAIVvnHsEus1+K/wLHNVpK9512rdEQCIGWmlSwX7bMS6uYSlT6jIP2b1qh0ygx2fLKVjNkZXv04yuI3iTUAqTOtr16amjr819y0wbE8sf4gVXYHkVpnrZRSHpGcnExubm6XC7LY7XafTzA9EWNoaCjJyb751X1hpZ1lW4+xdMtR8ivs9O0dyvfnDefGKQPObRaP0mzY8QrsXAZlORAUARdcAeNuhNTZnn3Iz1cE2CBlhvW69HeQv8M1kv0urPuV9Q+MIXOsRHpwBvTu5+2IVSf8K7FOmQmfvwSFX0LftHbNUwfH8fgHB/ksp4w5IxO8EKBSSp3/goKCGDRoUJd9MjMz3TaXs6f0hBjPlTGGT7NLWLLpKKu+LKCxyTB7WDwPXzGai0cmnP3c0nXl8OVyJnz+T8jcA4g1hVrGQ1YZREgvt36OHkUE+o23Xhf/DGqKrbppLe/oEfwvsQarHKSDxHriwBiCbMKmwyWaWCullPJLFbUOsvIq2H6sjOVf5HGoqIaosCBun5HKLdNSGBQfcXYndjqs2uAdS2HvCnDWExiebNUGj71eH7LrTES8tyNQZ8C/EuvoARA10FooZtq97ZrDgnU+a6WUUv6jtqGRXXmV7MwtZ2duBTtzy8kpqT3ZPm5ANH++bhyLxyYRGnQWJRnGQMFO2LEMsl6DmiJr9HXS7TDuRrburyBj9hz3fSClvMy/Emuw6qwPrLH+Y+/gAYapg+J4csMhqusb6RXif78epZRS56f6Rid786vYmVvODlcSfbCwmibXRCRJUaGMTY7iuvQBjE2OYmz/6LOfY7r8GOx6HXa+ai1BbQuG4QusmTiGzoPAYKvfgUy3fDalfIX/ZY4pM6yvoYr3WxOmtzFtcBxPrD/IZzmlZIzQchCllFI9jzGGg4XVbMh1sGZ5FjtzK9hbUInDaWXRcRHBjE2OYsGYJMYlR5GWHEVC5Dk+iFlXZk0QsPNV65thsKa1u+xRGH1Nj1g1T6lz5YeJdXOd9UcdJtYTU6KtOutsTayVUkr1LMfL63hzex5vfpHH/hPVAESGHCctOYo7Zw0+mUT3jw5zz1SHDrs1NVzWa3BgtTV3dNxQyPgJpH3Nmh9aKT/if4l17GBrKdIjn8DkO9s1hwcHMjY5ms2HdT5rpZRSvq/S7mBlVj7Lv8hj8+FSjIFJKTH8+qoxBJUc4vqFcwgIcOPczU1Oa3Aq61XY/Y4133REAkz+FqRdB/0m+M5c0Up1M/9LrEWsOusjH3daZz1tcCxPbcimpr6RCK2zVkop5WMaGpvYsL+IN7/IY82eEzQ0NjEoPoLvzxvOVeP7MzAuHBx2Mj866J6k2hgoyIKdr8CuN6AqH4J7Wctwp10Hgy6yFmVRys/5538FKTOsG0PZYWsEu41pg+P4+/pDfHakjIuG9/FCgEoppVRrxhg+P1rO8i9yeXdnPuW1DmIjgvnGpD58LaWG4XIMKVoLK/dC0V6oOMZFCGyJhrAYazaO8FjrPSzGtd3ivWV7cIQ18FR2xCrzyHrNOmdAIAy9BC79LQxfCMHh3v61KOVT/DSxnmW953zcYWI9KSWGwABhc3aJJtZKKaW86nBxDcu/yGPF59mElB9kdGAef+pTxoS+BcTVZiM7jsAOV2dbCMQPh4HTIP42jmQfJDWhN9SVQm0pVBdaCXJtGTRUdX5RWzCERlnT4wEMmGY9hHjB1RAR5/HPrFRP5Z+JdZ8REB5n1VlP/Hq7ZqvOOopN2VpnrZRSqvvVVFeybdUSCg9+TlT1Ia4JyOV7UkhAiGtuvPIgK4FOTocJX4eEkdBnFMSktirJyDGZpGZkdHyRxgawl1sJd3PiXVdqze7RvB2dYj2EGJPq6Y+s1HnBPxNrEasc5MhHnXaZNjiOpzdmU9vQSHiwf/6alFJKdS9jDBvWryJ14/e5kOM0YqMyMoWw/lMI6D8G+oyEhFHWt622s5xjullgMPRKsF5KKbfwaMYoIjlAFeAEGo0x6W3aM4C3gMOuXf8xxvzKkzGdlDIL9rxjTWIfPaBd89TBcfwj8xDbjpQxe5iWgyillPKsnUeL2LPs51xbs4wyWyz75z7P8GmLiW1eTEUp5fO6Yyh2jjGmuIv2D40xi7shjtZSZljvRz6B6BvaNaenxGALEDZll2hirZRSymMKq+y88NZqLt3/C24IyCYneTEDb3mCPuEx3g5NKXWG/LfGIXG09WDGkY9gXPvEOiKkuc661AvBKaWUOt/VNzp54aNsStc/wfdZQlNwOHWLnyN1/LXeDk0pdZYCPHx+A6wWkW0icncnfaaLyA4RWSkioz0cz1cCbDBwujVi3Ympg+LYmVtObUNjt4WllFLq/GaMYd2eE9z66BtcsO52HpIXaEq9kPDvbiFMk2qlejRPj1jPMsbkiUgCsEZE9hpjNrZo/xxIMcZUi8gi4E1gWNuTuJLyuwESExPJzMw840Cqq6vbHTegsS9DSt7nk1X/oSEktt0x4dWNOJyG59/ewOh42xlf0x0x+hJfjw80Rnfw9fhAY1Q918HCKn71zm5iDr3J88EvEhZiYMFfCZ90u65WqNR5wKOJtTEmz/VeKCLLgSnAxhbtlS22V4jIP0Qkvm1NtjHmaeBpgPT0dJPR2dRBXcjMzKTdcbmRkP0CM/oDY9qfM72+kce+WE1dZDIZGSPO+JpuidGH+Hp8oDG6g6/HBxqj6nkq6hw8tvYAb3+axW+Dn+PS4E00JU8h4OqnIG6It8NTSrmJxxJrEYkAAowxVa7t+cCv2vTpC5wwxhgRmYJVmtJ9k0cnjYOgCGt58zHXtGvuFRLImP5RbD6s81krpZQ6c84mwytbj/Hn1fsYa9/CB+HPEtlUCXN+TsDM71lliUqp84YnR6wTgeVifbUVCLxsjHlfRO4FMMY8BXwN+C8RaQTqgBuNMcaDMbVmC4SBU7uss542OJbnPjpMXYOTsGC9ASqllDo9m7NL+OU7u8nJL+SvMW8w3/kexIyCa96EpLHeDk8p5QEeS6yNMdnAuA72P9Vi+wngCU/FcFpSZsIHv4aakg6XaZ02OI5/bsjm86NlzBwa74UAlVJK9STF1fX8+t3dvLX9OPMjj/Ba3JOE1xyD6d+GuT+DoFBvh6iU8hD/nW6vWcpM6/3opzCq/XTa6SkxBIg18qCJtVJKqc4YY3htWy6/fW8PjQ31vDJ0HVPyXkTCk+H2dyF1lrdDVEp5mCbW/SdCYKhVZ91BYh0ZGkRaf53PWimlVOdyimv4yfIsjmbv4Wexm7kyPJOg3HwYfyss+D2E9vZ2iEqpbqCJdWAIJE+2EutOTBscx/Mf51Db0Eh4sP7KlFI9l4g8BywGCo0xY1z7/gRcDjQAh4A7jDHlHRybA1QBTqDRGJPeXXH7Koeziecy97Avcyn3B2QyLSQLUyPI0Hkw9QkYNs/bISqlupGnF4jpGVJmQkEW2Cs6bM4YkUCDs4n1e4u6OTCllHK7F4AFbfatAcYYY8YC+4GHujh+jjFmvCbVUJZ/iBV/+Do3bLyE/7X9jclR5TDnp8j3d8Gtr2tSrZQf0uFXgNSZsKEJjm6C4Ze2a54yKJb4XsGsyMrnsrFJXghQKaXcwxizUURS2+xb3eLHTVgzNqmO2Cuo3/4axRuf4eravTQQSMnA+URn3I1t0EUQoONVSvkzTawB+qdDQJBVDtJBYm0LEC4d3Zf/fJ6n0+4ppc533wRe6aTNAKtFxAD/dC3edf4zxnrA/fP/w7nrP4Q47VQ1DeDl3rdz+Z0/ISkm0dsRKqV8hCbWAMHh0H8S5HReZ31ZWhJLNh8lc18hC9N01Fopdf4RkZ8CjcCSTrrMMsbkiUgCsEZE9hpjNrbtJCJ3A3cDJCYmntXS7r6wJHxQQzl9Cz4gKX8N4XXHqSWMNxtnsC5kLtPGjiIp2M62HXuAPV6Nsyu+8Hvsiq/HBxqjO/h6fOC+GDWxbpYyAz55HOqrIaRXu+Ypg2KJiwjmvax8TayVUucdEbkd66HGiztbqMsYk+d6LxSR5cAUoF1i7RrJfhogPT3dnM3S7l5dEr6mBN7/MXy5HJoaKYqZwO/rruJtxxTunDuGJy8aQnBgQI9Ytt7XY/T1+EBjdAdfjw/cF6Mm1s1SZ8JH/wu5W2DI3HbNgbYALh3Tlze/yMPucBIapOUgSqnzg4gsAH4EXGSMqe2kTwQQYIypcm3PB37VjWF2j5yP4I27oLaYirF38su8dP5zLIIpqbG8cU0aQxPaD7wopVQzfcqi2YCpILYulze/LC2J2gYnmfsKuzEwpZRyHxFZCnwKjBCRXBG5E2sF3Eis8o7tIvKUq28/EVnhOjQR+EhEdgBbgPeMMe974SN4RpMT1v8eXrwcgsJ4a9KLTP5sDmuKovj9NWksu3uaJtVKqVPSEetmIZGQNK7LOuupg2KJjQjmvawCFozRchClVM9jjLmpg93PdtL3OLDItZ0NjPNgaN5TkQf/uct6gH3sjewa/zO++/QO5o7swyPXpJHQW5cgV0qdHh2xbillBuR9Bg57h82BtgAuHd2XdXtOYHc4uzk4pZRSbrdvJTw1E45vh6uewlz9FL9ec4y4iGAeu3G8JtVKqTOiiXVLqbPA2WAl151YlNbXVQ6ii8UopVSP1VgPKx+EpTdCVDLcsxHG38S6PYVsPlzK9+YNIzI0yNtRKqV6GE2sWxo4DZAu66ynD44jJjyIFVn53ReXUkop9yk+CP+aB5ufhKn3wrfWQfxQHM4mfrdyD4P7RHDjlIHejlIp1QNpYt1SWAwkjrGeCu+EloMopVQPtmMZ/PNCqDgGNy6FhX+AwBAAlm09RnZRDQ8uGEmQTf88KqXOnN452kqdCce2QGNDp10WpSVR0+Bk434tB1FKqR6hvhqW3wvL77EeVL/3Yxi56GRzld3BY2v3M2VQLJdcoCspKqXOjibWbaXMgMY6yN/eaZfpQ+KI1nIQpZTqGfJ3WKPUO1+Bix6Eb7wDUf1bdfnnhmyKqxv46aJRiIiXAlVK9XSaWLeVMtN676IcJMgWwKUX9GXtnkItB1FKKV9lDGx6yqqndtTCbW/DnIfA1nqm2fyKOv71UTZXjOvHuAHRXgpWKXU+0MS6rYh4iB/R5QOMAIvGJlFd38iHB4q7KTCllFKnrbYUlt5kLU0+ZK5V+jFododdH129n6Ym+OGlI7o5SKXU+UYT646kzoSjm8DZ2GmXGUPiiArTchCllPI51UXw1Cw4uBYWPAI3LYOIuA677j5eyRuf53LHzFQGxIZ3c6BKqfONJtYdSZkJDVVwIqvTLkG2AOZfkMja3Seob9RyEKWU8hnbl0BlHtz+Hkz7L+ikZtoYw+9W7CEqLIj/njO0m4NUSp2PNLHuSMoM672L5c3BKgepqm/kw/1aDqKUUj7BGNixFAZMhYFTu+y6YX8RHx0s5v65w4gK08VglFLnThPrjvTuBzGDTllnPXNIPL1DA1mxS8tBlFLKJ+TvgKK9MO7GLrs5mwy/X7GXlLhwbp2W0k3BKaXOd5pYdyZ1Jhz9BJqaOu0SHBjA/NF9WaPlIEop5Rt2LAVbCIy+ustur287xr4TVfx4wUiCA/VPoVLKPfRu0pmUmVBXBkV7uux2WVoSVfZGPj6o5SBKKeVVTgdkvQYjFlor6Xaipr6RR1fvZ+LAaBaO6duNASqlzneaWHfm5HzWXddZzxxqlYO8t7OgG4JSSinVqYNrobYExt3UZbdnPsymsKqen16mi8EopdxLE+vORA+E3slwpPOFYsAqB7nkgr6s2V1AQ2PnZSNKKaU8bMdSCI+HoRd32qWw0s7TG7NZlNaXSSmx3RicUsofaGLdGRGrzvrIJ9ZT5l24bGxfKrUcRCmlvKe2FPathLHXg63zGT7+snY/DmcTP7p0ZDcGp5TyF5pYdyVlJtQUQfGBLrvNHBpPZEgg7+liMUop5R1fLgdnQ5ezgew/UcUrW49x67QUUuMjujE4pZS/0MS6K8111ke6rrMOCbRxyQWJrP5Sy0GUUt1DRAJEZIKIXCYic0UkwdsxedWOZZBwAfQd22mX36/YQ0RIIPfPHdaNgSml/Ikm1l2JGwK9Ek+ZWAMsSkui0t7IJ4e0HEQp5TkiMkREngYOAo8ANwH/DawVkU0icoeI+Ne9veQQ5G6xRqs7eRjx44PFrN9XxLfnDCUmIribA1RK+Qv/uvmeKRFrFcacj09ZZz17uFUOskLLQZRSnvUb4N/AEGPMpcaYW40xXzPGjAWuAKKAr3s1wu62YylIAKRd32FzU5Pht+/toX90GN+Ykdq9sSml/Iom1qeSMhOqjkNZTpfdQgJtzLsgkdW7T+BwajmIUsozjDE3GWM2GtP+X/vGmEJjzF+NMS96IzavaGqCHa/A4DnQO6nDLsu/yGN3fiU/WjCC0CBbNweolPInmlifysk6666XNwerHKS81sEnh0o8HJRSSllEZKiI/FtE3hCR6d6Op9sd/QQqjnY6d7Xd4eTPq/cxNjmKy8f26+bglFL+RhPrU+kzEsJiT6vOevaweHqFBLJip5aDKKU8Q0RC2+z6NfAQ8D3gye6PyMt2LIXgSBh5WYfNz350mPwKOz9ZNIqAAF0MRinlWZpYn0pAgFVnfRqJdWiQjXmjEli1u0DLQZRSnvKOiNzW4mcHkAqkAE6vROQtDbXw5Vsw+koIDm/XXFxdz5OZh7jkgkSmDY7zQoBKKX+jifXpGJxh1Vgf+uCUXZvLQT7VchCllGcsAHqLyPsiciHwAHApcDVwi1cj625734OGqk7LQB5fd4A6h5MHF+piMEqp7uHRxFpEckQkS0S2i8hnHbSLiDwuIgdFZKeITPRkPGdtwtchdgi8+wNw1HXZ9cLhfYgItrFyl5aDKKXczxjjNMY8AdyANQvIY8Dzxpj/Mcbs9W503WzHUogaCANntGs6VFTNks1HuXnKQIb06eWF4JRS/qg7RqznGGPGG2PSO2hbCAxzve7GV+sDg0Jh8V+g7DBs+GOXXUODbFw8KpFVX56gUctBlFJuJiJTReR1rPvlC8D/A34rIo+KSPRpHP+ciBSKyK4W+2JFZI2IHHC9x3Ry7DdcfQ6IyDfc9JHOTmU+ZK+HcTdYJXttPLJyL2FBNr47TxeDUUp1H2+XglwJvGQsm4BoEel4viRvG3wRjLsZPnkcTnzZZddFaUmU1jSwKbu0m4JTSvmRfwL3Aw8D/zTGHDLG3Ai8DbxyGse/gFVO0tKDwDpjzDBgnevnVkQkFvgFMBWYAvyiswS8W2S9CqYJxrZfwnz7sXLW7D7BvRcNJr5XiBeCU0r5q0APn98Aq0XEYP0BeLpNe3/gWIufc137WtVRiMjdWCPaJCYmkpmZecaBVFdXn9VxLQVFLGRKwDvULrmDLyY8Yi1I0IEApyHUBv9atY3GvNO/qbsjRk/y9fhAY3QHX48P/D7GRqyHFSOAhuadxpgNwIZTHWyM2SgiqW12XwlkuLZfBDKBH7fpcymwxhhTCiAia7AS9KVnFr4bGAPbl0LyFIgf2q75+Y8PExkSyO0zB3V7aEop/+bpxHqWMSZPRBKANSKy1xiz8UxP4krInwZIT083GRkZZxxIZmYmZ3NcOwk1RL15Lxm9smHytzrtdknhF3x8sJhZsy8k0HZ6Xwy4LUYP8fX4QGN0B1+PD/w+xpuBe7CS6ttO0fd0JRpjmgc0CoDEDvp0NhDSjqcHQ3pVZZNetIf9w+7leJs+ZfYm3t1Rx8UDA/ns04/O+LruitFX+HqMvh4faIzu4Ovxgfti9GhibYzJc70XishyrK8PWybWecCAFj8nu/b5rnE3Wg/MrP0ljLis05W+Lkvryzs7jrP5cCkzh8Z3c5BKqfPYAWPM/3TVQUSko5UZT4cxxri+ZTxrHh8MeX8V2IIZfvWPGR4e26rpf9fsp4kD/OS6WaTGR5zxdd0Wo4/w9Rh9PT7QGN3B1+MD98XosRprEYkQkcjmbWA+sKtNt7eB21yzg0wDKlqMmvgmEetBxsZ6eL/tN6VfyRiRQHiwjfeyfPvjKKV6nPUi8h0RGdhyp4gEi8hcEXkRONMHC080P9/iei/soI9vDIQ4HbDzVRi+ANok1fWNTl7efJS5IxI8nlQrpVRHPPnwYiLwkYjsALYA7xlj3heRe0XkXlefFUA2cBB4BvhvD8bjPnFD4KIfwu63YN/7HXYJDbIxd2QCq3YV6OwgSil3WoC1EMxSETkuIrtFJBs4ANwE/NUY88IZnvNtvkrGvwG81UGfVcB8EYlxPbQ437Wvex1cB7XFMP7mdk0rsvIprq7n9pmp3R6WUkqBB0tBjDHZwLgO9j/VYtsA93kqBo+a8V3IegNWPACpsyCk/Typi9KSeHdnPltySpkxRMtBlFLnzhhjB/4B/ENEgoB4oM4YU346x4vIUqwHFeNFJBdrpo9HgFdF5E7gCHC9q286cK8x5lvGmFIR+TWw1XWqXzU/yNitdiyF8DgYOq/VbmMMz3+cw9CEXszS8jullJd4e7q9niswGC7/K1Qcg/W/67DLnBEJhAXZWKHlIEopDzDGOIwx+aebVLuOuckYk2SMCTLGJBtjnjXGlBhjLjbGDDPGzGtOmI0xnxljvtXi2OeMMUNdr+c98Zm6VFcG+1ZC2nVgC2rV9MWxcnbmVvCNGamISLeHppRSoIn1uRk4DSbdAZufhONftGsOC7bKQd7fdQJn0zk9C6SUUurL5eCstx4ib+OFj3OIDA3kmgkdTlSilFLdQhPrczXvYYjoA+98F5yN7ZoXpSVRXF3PlsO6WIxSSp2THcugzyhIGt9q94lKOyuy8rkhfQARIZ6eRVapnqGusY53Dr3DvWvv5f4P7mfJniUcLDvIWU4YpE6T3oHOVVg0LHgEXr8DtvwTprcuGZ8zsg+hQQGsyMpn+pA4LwWplDrfiMh3gH8bY8q8HUu3KDkExzbDvF9aszO1sGTTEZzGcNv0VO/EppSPMMawo2gHbx58k/dz3qfGUUNyr2QA1h9bD0BcaBxTkqYwte9UpiZNJTky2Zshn3c0sXaH0VdbD9R88FsYdQVEfzUjVXhwIHNHJrByVwEPXzEaW4DW/iml3CIR2CoinwPPAavOdu7qHmHnK4DA2Otb7a5vdLJk81EuHpnIwLhw78SmlJdVNFbwbNazvHXoLQ5XHCYsMIz5KfO5auhVTEqchIiQV53HlvwtbMrfxJaCLaw8vBKA/r36M6XvFKYmTWVK3yn0Ce/j5U/Ts2li7Q4isOjP8I9p1iwhNy1rNaKyKC2JFVkFbDxQxJwRCV4MVCl1vjDG/D8R+RnWtHd3AE+IyKvAs8aYQ96Nzs2amqzBi8EZ0Ltfq6Z3d+RTUtPAHTrFnvIzDqeDzNxMlh9Yzkd5H2HyDBMTJnLHjDuYnzqfiKDWc7n379Wfq4ddzdXDrsYYw+GKwyeT7LVH17L84HIAhkQNOTmind43naiQqHbXNsZQ2VBJib2E0rpSSu2llNnLKLWXWvvspa1elfWVhC0JIyIogoigCMKDwq3twBbbzfsDI9r16xXUi8HRgwkKCGoXi685rcRaRIYAucaYehHJAMYCL53Jk+jnvZgUmPNTWP1Ta37r0VedbJo3KpFB8RH89D9ZrPzuhUSF+/7/MZRSvs+1SmIB1jLkjUAM8LqIrDHG/Mi70bnR0U+h/CjM/Vmr3cYYXvgkh2EJvZihpXbKT+wt3cubB9/kvez3KK8vJyEsgXm953H/3PtJjUo9rXOICIOjBzM4ejA3j7oZZ5OTvWV72ZK/hc35m3nz4Jss3bsUQRgVN4qU3imU28tPJspl9jIaTfvnygCiQqKIDY0lNjSWodFDiQ2NpSy/jIT+CdQ21lLjqKHGUUOto5b8mnxr27W/3lnfacyRQZHM6j+LjAEZzOw/s8OE3xec7oj1G0C6iAzFWqb2LeBlYJGnAuuRpt4LWa/Cyh9bIyth0YC1WMxjN47nmn98wkPLd/L3myfqdFBKqXMiIt8FbgOKgX8BPzTGOEQkAGuxmPMnsd6xFIJ7wcjLWu3+/GgZWXkV/PbqMXpPVee1cns57x1+jzcPvsne0r0EBQQxZ8Acrh52NdOTpvPhxg9PO6nuiC3Axui40YyOG80dY+7A4XSQVZzF5vzNbMrfxM6incSFxpEUkcTo+NEnE+eWr7iwOKJCojocVc7MzCRjSsYp43A0Oah11FLrcCXgjVYSXm4vZ3PBZjKPZbIyZyWBEsjExIlkDMggY0AGAyIHnPLc3eV0E+smY0yjiFwN/M0Y8zcRaT+/nL+zBcLlj8Ezc2HdL62lz13GJkfzwKUjeGTlXl797Bg3TB7YxYmUUuqUYoFrjDFHWu40xjSJyGIvxeR+jjr48k244EoIbv3V9vMf59A7NJCrdYo9dZ7aXbKb53Y9xwdHP8DR5GBU7CgemvIQiwYtIjo02mPXDbIFMTFxIhMTJ/Jf4//LY9dpd92AIKJCojocjV40eBFNpoms4iwyj2WSeSyTP279I3/c+keGRg/9/+3dd3wUdf7H8dcnvfcQQgIJJHQILUgRIdjpiHqAh4Ll0PMUzt7uvPuh51nOO8UOKMWCHY2IoqKhKCA1gdBCCb0k9FBTvr8/ZsEAAQPs7mySz/PxmMfOzszuvDNshk9mv/P9niyyW8a0xEvs6/SusoV1sYgMxhrqto9jmbZnqEidNtaV63mvQ9ogqNfh5KrhlzVgdl4B/8xcQbukKFJrnTlao1JKVdI3wMl+PEUkDGhqjJlvjFlpXywnW/U1HD94Rt/V2/cf4ZvlO7jt0mSC/PR2IVW9rNi9gjey3yBrcxahfqEMbDyQ/qn9aRzV2O5otvIS9i7gbAAAIABJREFUL1rFtqJVbCtGth3J5oObmbl5Jlmbsxi/fDzjlo0jOiCabnW7kZGYQcc6HQn0CXRrxsqejW4F7gL+ZYzZICL1gXddF6uK6/4ErMi0+ra+c5Y1SiPg5SX89w+tufalWYz8cAmf390Zfx9vm8MqpaqoN4C25Z4XVbCs6sueDOF1IanLKYvfn7eJMu1iT1UzubtzeXPpm2RtsQrqe1rfw01NbyLUL9TuaB6pbmhdhjQbwpBmQ9h/bD8/b/2ZrM1ZfJf/HZ/nfY6/tz8d4zuSUTeDbond3NLjSaUKa2PMCmAEgIhEAqHGmOdcGaxK8w+BXv+ByYPgl9HQ9cGTq+LCAnjhhlbcMWkhL3y7mr/1bmZjUKVUFSblu9dzNAGpXpduD+6AdT9Cl/vB67evdo8Wl/LBr5u4smkcdaO0iz1V9ZUvqMP8wrSgvgDh/uH0bNCTng16UlxazKJdi042GZm5ZSZta7VlYo+JLs9R2V5BsoC+ju0XAbtE5GdjzP0uzFa1Ne5h9Wk983mrn+volJOrrmwWxy2dkhg3ZwNdGsaQoV3wKaXO33oRGYF1lRrgbmC9jXmcb9knYMrOaAbyVfY29hw6zq2dk+3JpZSTnF5Q39vmXm5qchMhftpU9GL4evvSMb4jHeM78kj7R8jbl8eRkiNu2Xdlr26EG2MOiMgdWN3s/UNEclwZrFro8Tysz4Kp98EtX57St/XjPZsyf/0eHvwkm29GdiU21N++nEqpquguYDTwN8AAM4DhtiZyJmNg6WRISIeYhuUWW13sNYoL0dFs1Tmt27eOV5e8yrHSY8QHxxMfEk/t4NrWfHA8sUGxtvWLnFuYyxvZbzBzy0wtqF1MRGgU2cht+6tsYe0jIvHAH4AnXJinegmLhyuetAaNyfnolKsuAb7ejB7chr6vzuGhT7N5Z2h7G4MqpaoaY8wuYNDvblhFhRRtgF250OvFU5Yv3LiX3G0HeOa6ltrFnqrQ0ZKjjF02lneWv0OQTxB1QuqQU5jD/mP7T9nOS7yIDYw9WWjXDvmt6I4PtorwML8wp2YrX1CH+4czos0IBjcZrAV1NVLZwnoUMB342RizQEQaYPWTqn5P+u1WUT39cUi5AkJ+azjfuHYof+vVlL9/mcuEX/JpYGNMpVTVIiIBwO1AcyDgxHJjzG22hXKiuJ0/gZcvNB9wyvIJP+cTHuhL/zZ1zvJKVZPN3TaXp+c9zaaDm+jToA8PpD9AdKD1zcbh4sPsOLyDHUU72H5o+8lpx6EdLN+9nB82/UBxWfEp7xfkE0QIIYz/ZjxRAVFEBkQSGRB5Sv/NJ55H+Efg41VxWbW8cDlvZL/BrC2ztKCu5ip78+InwCflnq8HrndVqGrFy8vq23pMd5jUD4ZmQnDMydVDOiYxc00hz36ziic6+NkYVClVxbwLrAKuwbr48UegenSzV1pC3M6Z0PhaCIo6uXjbviN8m7uDO7rU1y721Cl2H9nNCwtf4Ov1X1MvtB5jrx5Lx/iOp2wT5BtEg/AGNAiv+DJWmSljz9E9bC/afkrhvWLjCry9vMk/kM/iXYvZd2wfZaaswvc4MepgpH8k0YHRRPpHsu3QNuZsnUO4fzgj245kcJPBZww3rqqPyt68mAi8AlzqWDQbGGmM2eKqYNVKXHO46UOYPBgm9LaK6xDrhkUR4fkb0rj2pVm8mX2MP1xbSqCfdsGnlPpdqcaYG0WknzFmooh8gHVurvrWzcCveD+0GnzK4vfmbcQYw5COSTYFU56mzJQxJW8K/130Xw6XHObOtDv5U9qf8Pc+//uWvMSLmMAYYgJjaBnb8uTyrMNZZGRknHxeWlbK/uP72Xt07ylDfJ+YP/F8/b717Dm6B28vby2oa5DK/sk/HmsI8xsdz4c4ll3lilDVUsrl8MdP4IOBMKEX3JJptcEGooL9+N/A1gwZN59RU1fw7wEtf+fNlFKKE99Z7xORFsAOoHp0MbR7HUf9owlI/e2/mKPFpUz+dRNXNdMu9pRl3b51jJo7isW7FtO2Vlv+0ekfNIhwfaNKby/vk81AUkj5/ReoGqWyYz7GGmPGG2NKHNMEwPW9bFc39bvCkM/gwDaruN6/9eSqS1Nj6FHfl8m/buLb5dttDKmUqiLGOMYV+BuQCawAqsf4Ap3uZn6Ht04OrgWQuXQbew8XM6xzfRuDKU9wtOQooxeP5oavbmDtvrWM6jyK8deOd0tRrdTvqWxhvVtEhoiIt2MaAux2ZbBqK6kzDPkcinbBhJ6wb9PJVQMa+pKWGM4jny1j2z739LeolKp6RMQLOGCM2WuMmWWMaWCMqWWMecvubM5iynWDZoxh/C/5NKkdSscGUed4laru5m6by4DMAYxdNpYeyT3I7J/JdQ2vw0sqW84o5VqV/STehtXV3g5gO3ADMMxFmaq/eh2sfq0P74XxvWBvPgA+XsLoQW0oLi3jvo+WUlpmzv0+SqkayRhTBjxsdw53+XXDHlZuP8CwzsnaxV4NtfvIbh6d/SjDvx+OIIy9eizPXPbMyR4/lPIUlSqsjTEbjTF9jTGxjqsi/dFeQS5OYjvrJsZjB2B8T9i9DoDkmGBG9WvB/A17eCNrrc0hlVIe7AcReVBE6opI1InJ7lCuMOGXfCKCfOnXOsHuKMrNykwZn635jL5f9GV6/nTuTLuTz/t9fkaPH0p5iovpr+h+4CVnBamR6rSGYVOtbvgm9CKw6d8AuL5tArPWFPC/H/LolBJDu6RIm4MqpTzQQMfjX8otM1C9usTfuu8I03N3MLxrivaYVAMYYyg8UsiavWvI25vHjE0zWFqw1K03Jyp1MS6msNbv45yhdksYOhUm9aXNkicgPR2p1YSnr2vB4k17GfnhEqaNvIywAHuGXVVKeSZjTI24i+/duRsBuLmTdrFX3RwpOcLGYxuZkjeFNXvXnCym9x7be3Kb+OB4RnUeRb/UftqOWlUJF1NYawNgZ4lrBsO+xoy9xuotZGgmYXHNeXlQG/7w1lz+NmU5Lw9qrW0LlVInicgtFS03xkxydxZXOXK8lA8XbOKa5rVJiAi0O466QGWmjK0Ht7Jm32/Fc97ePDYe2IjBwA4I9AkkNSKVy+tdTsPIhjSKbETDiIZEBETYHV+p83LOwlpEDlJxAS2AnuWcKbYxS1v/iw4rn7YGkbnlS9olpfHXKxry4vdr6NYoluvbJdqdUinlOdqXmw8ArgAWA9WmsP5y6Vb2HS5mWOdku6NUOcdLjzMhdwL+x85/oBRnKC0r5dM1n5K5PpO8vXkcKbF6uhKEemH1aBjRkJ71e3Js2zEGdBlAYmiiXpFW1cI5C2tjTKi7gig4EpQAt34NE/vCxD5wyxfc3b01s9cW8uSXy2mXFElyjI7apJQCY8y95Z+LSATw4YW+n4g0Bj4qt6gB8KQx5qVy22QAXwIbHIs+N8aMutB9nosxhgm/5NM0PoxL6lfLezJdprSslEdnP8r3G79HEDbN3cSItiMI9w93y/5X7F7BU3OfYvnu5TSLbsaAhgNOXoFOiUghyPe3AX6y9mVRL6yeW3Ip5Q4X0xREuUJUAxj2NUzsDRP74X3z57w0sDU9Xp7NrRMW8OHwjsSFBdidUinleQ4BF9zu2hizGmgNICLewFZgSgWbzjbG9L7Q/VTWqj1lrNpxmOevT9NmcOfBGMPT85/m+43fM6LNCJatXcZneZ/xw6YfuK/dffRL6eey41l0vIhXl77K5FWTifSP5NnLnqVn/Z7676dqFP3exRNFJsGwaRAUBZP6U+dANu8MS2fXgaMMHjOPnQeO2p1QKWUzEflKRDId01RgNRUXwhfiCmCdMWajk97vvP2wqZjIIF/6tq5jV4Qq6ZUlr/Dpmk+5vcXt/CntTwyIGsBHvT+ibmhd/v7z3xn27TDW7F3j1H0aY5ieP52+X/Tlg5UfcGOjG8m8LpNeDXppUa1qHC2sPVVEXbh1GoTGwbsDaGdWMvG2S9h54CiDx85jlxbXStV0/wFedEz/BroaYx510nsPAiafZV0nEckWkW9EpLmT9neKzXsOs3hnKYMvqUeAr3axV1nvrXiPscvGcn3D6xnZduTJ5Y2jGjOpxyRGdR7F+v3r+cNXf+A/C/7DoeJDF73PzQc28+cZf+bBmQ8SExjD+z3f528d/0aYX9hFv7dSVZE2BfFkYXUczUL6wvs3kH7dW0y49VKGjl/A4LHzmDy8I7VCtVmIUjXUJmC7MeYogIgEikiyMSb/Yt5URPyAvsBjFaxeDCQZY4pEpCfwBdCwgvcYDgwHiIuLIysr67wyfLz6OIIhxWwjK2vHef4E7lNUVHTeP5urLChawKTdk0gLTOOyY5cxc+ZM4NSMkUTyaOyjZO7LZOKKiXy5+ksGRA6gddD59zpVbIr58cCPTN8/HW+8uT7yei4LuYzdubvJIqvS7+NJx/BsNOPF8/R84LyMWlh7utDa1iAy7w2Aj2+mff2ufNz3Yf6QeYjBY+bx4fBOxIbac9e3UspWnwCdyz0vdSxrX/HmldYDWGyM2Xn6CmPMgXLz00TkdRGJMcYUnrbdGGAMQHp6usnIyDivAG07FtMocybX97j8QvK7TVZWFuf7s7nCrC2z+ODHD7ik9iW8fuXr+Hv/9n9CRRl70Yvsgmyenvc07xS+Q+c6nXm8w+MkhVWur/AFOxbw1Lyn2LB/A1cnXc3D7R8mLjjugrJ7yjE8F8148Tw9HzgvozYFqQpCasGffoIeL8CO5bSY2oeZDT+mdN9WBo+dR8HBY3YnVEq5n48x5viJJ455Pye872DO0gxERGqL49KmiFyC9X/Ibifs8xRhAb60rqXXfSpj6a6lPJD1AA0jG/Jy95dPKarPpVVsKyb3msyjlzxKTkEO1315Ha8tfY2jJWdvZrj7yG4en/04t02/jeLSYt648g1ezHjxgotqpaojLayrCm9f6DAcRi6FS0cQm/8VM/zu5/p9E7h9zI9aXCtV8xSISN8TT0SkH1B4ju1/l4gEA1cBn5dbdpeI3OV4egOwXESygdHAIGOMDhZmk7y9edw9427iguN448o3CPELOa/X+3j58MemfySzfyZXJV3Fm9lvct2X1zF7y+xTtiszZXyy5hP6fNGHb/K/YXjacKb0m0KXhC7O/HGUqha0sK5qAsLhqlFwz0K8m/biz16f8/aBO3nv9f+j8MDF34iilKoy7gIeF5FNIrIJeAS482Le0BhzyBgTbYzZX27Zm8aYNx3zrxpjmhtjWhljOhpjfrmon0BdsK1FW7nr+7sI9A7kraveIjow+oLfKzYolue6Pse4q8fh6+3L3TPu5r6f7mPHoR2s3rOam7+5mVFzR9Ekqgmf9f2Me9vcS4CP3t+jVEVc/l2boz/UhcDW0/s+FZFhwAtY/aUCvGqMGefqTNVCZBLc8A50vBv/Lx/mvoLX2PDSVPyue46wlj3sTqeUcjFjzDqgo4iEOJ4X2RxJucnuI7sZ/t1wjpYeZcK1E0gISXDK+3aI78BnfT5j4oqJvJX9FnOmzKG4rJhw/3Ce6fIMvRv01u7zlPod7rhiPRJYeY71HxljWjsmLarPV2I6YXfPYFXX1/AqPUrYZ4M4PqEf7My1O5lSyoVE5BkRiTDGFDl66YgUkaftzqVcq+h4EX/+4c/sOryL1654jYaRZ3TKclF8vX25o+UdfNH/C7rX7W71Sd0/kz4pfbSoVqoSXFpYi0gi0AvQgtmVRGhy+RC23pTFM6U3c2zjQsybXSDzXjjouV1VKaUuSg9jzL4TT4wxe4GeNuZRLnas9BgjfhpB3t48Xsx4kda1WrtsXwkhCTzf7Xme6PiE24ZCV6o6cPUV65eAh4Gyc2xzvYjkiMinIlLXxXmqtc6N69D1ln9yRfFLTPHrg1k6GUa3hazn4Li2v1aqmvEWkZNdQIhIIKB9b1ZTJWUlPDLrEauruy5P0TWxq92RlFIVcFkbaxHpDewyxiwSkYyzbPYVMNkYc0xE7gQmAmd0XHqxgw1Azeqc/JbWUTyyeCAfB3Xnf6EfEZ/1DMd+eZP85EHsjOtGmfeF3XRSk46hK3l6Rk/PB5rR4X1ghoiMdzy/FZjkyh0qexhjeGreU8zYNINH2j9C7wa9f/9FSilbuPLmxUuBvo7RuQKAMBF5zxgz5MQGxpjy/Z+OA56v6I0udrABqFmdk2cAaWkF3DFpIbeHPsGHgyFs1j9pvOZ1Gm98D1oNgna3QlwzW/K5kma8eJ6eDzQjgDHmOUe3d1c6Fj1ljJnush0q24xeMprP8z7nTy3/xJBmQ37/BUop27isKYgx5jFjTKIxJhkYBPxYvqgGEJH4ck/7cu6bHNV56NoolrG3pLO2oIjB02HfTdPg1m+h0bWwaCK80QnevhqyP4TiI3bHVUpdAGPMt8aYB40xDwKHROQ1uzMp55qUO4lxy8ZxY6MbubfNvXbHUUr9Drf3Yy0io8oNajBCRHIdV11GAMPcnac669YoljE3tyNvZxFD3vmVfbHt4Pqx8MAquPpfcHg3TLkTXmwC3z4GBWvsjqyUOg8i0kZEnheRfOApYJXNkZQTZa7L5IWFL3BV0lU80eEJ7ZVDqSrALWPGGmOygCzH/JPllj8GPOaODDVVRuNavHVLO+6ctIhBY+Yx5uZ06kVHQed7oNNfIH82LBwPv46Fea9DUhdIvxWa9gEfvQ9KKU8jIo2whh0fjDXS4keAGGO62xpMXbSSshLW7F3Dkl1LWLRzET9u+pEO8R149rJn8fbytjueUqoS3FJYK3t1b1yLcUPTueeDxfR6ZTb//UNrrmoWByJQv6s1FRXA0vdg0QT47HYIiobWf4R2wyA6xe4fQSn1m1XAbKC3MWYtgIjcZ28kdSGOlBxhWcEyFu9azJJdS1i6aymHSw4DUCe4Dv1T+/NQ+4fw8/azOalSqrK0sK4hujaK5esRl3H3+4v506SF3NmtAQ9d3Rgfb0droJBY6HIfdB4J63+CReNh7mvwy2hokAHtbkXKQuz8EZRSlgFY9638JCLfAh8C2kagCth7dC9Ldi1h8U6rkF6xewUlpgRBaBjZkD4pfWhbqy1t49pSO7i23XGVUhdAC+sapG5UEJ/c1Ymnv17BWzPXs2TjPl65qQ1xYeW63/PygtQrrOnAdljyHiyeCJ8MpbNPKGxoBhH1rCm8rmM+CcITwffCuvFTSlWeMeYL4AsRCQb6AX8FaonIG8AUY8x3tgZUgNVF3paiLScL6cW7FrNh/wYAfL18aRnTkmEthtGmVhtaxbbSQViUqia0sK5hAny9ebp/S9KTonjs82X0Gj2b0YPb0Dkl5syNw+Kh20Nw2f2wdgaFP75FvPcx2Pwr5E6BspJTtw+p7Si06/5WfJ9SeAe654dUqgYwxhwCPgA+EJFI4EbgEUALaxvsPbqX5YXLWb57ObmFuSwrXMaeo3sACPULpU2tNvRN6Uu7uHY0i26Gv7few6JUdaSFdQ3Vv00CzeuEcdd7ixgybj4PXN2YP3dLwcurgm+Uvbyh0dWs3uZH/Il+eUtL4OB22L8Z9m1yTButx62LYEUmlBWf+j4htaHFALh0JITq15xKOYtjOPOT/f0r1zpcfJgVu1cwY/8Mps6cyvLC5Wwt2gqAINQPr0+XhC60jGlJ27i2pEak4iVu74RLKWUDLaxrsIZxoWTe04XHPl/GC9NXszB/D/8b2JqIoErcKOPt47gyXReSOp+5vqwUDu4oV3Rvgl25MP8tWPiOdVPkpX+1roorpZSHKi4tZs3eNSevRi8vXM76/espM2UA1CmuQ/OY5gxsPJAWMS1oGtWUED+9H0WpmkoL6xou2N+Hlwe1pn39KJ76agW9Rs/h9T+2pVXdiIt7Yy9vCE+wpqROvy3fsx5mv2h177dwvFVgd/krhNW5uP0ppZSTFJcWM27ZOGZvnc2qPasodnz7FhUQRfPo5lyVdBUtYlqwf/V++lzRx+a0SilPooW1QkS4uWMSaQnh3P3+Ym548xf+3rsZN3dMcv6ABFENoN9r0PUhq8Be+LbVA0nboVavJOEJzt2fUkqdh8IjhTyQ9QCLdy2mXVw7hjQdQvOY5rSMaUl8cPwp58SstVn2BVVKeSQtrNVJrepG8PWILtz/cTZPfpnLgvy9PDugJcH+LviYRCZD31fgsgetAnvReKv3kTY3WzdLhic6f59KKXUOOQU53PfTfRw4foDnuz5Pj/o97I6klKpi9G4KdYqIID/G3ZLOw9c25uucbfR9dQ5rdh503Q4jk6DvaBixxBqQZvEkeLk1TL0P9m123X6VUqqcz/M+Z9i3w/D19uW9nu9pUa2UuiBaWKszeHkJd2ek8v4dHdl/pIR+r/7MlCVbXLvTiHrQ5yWrwG57Myx+F0a3ga/+at34qJRSLlBcWsxTc5/iH7/8g/a12/NR749oHNXY7lhKqSpKC2t1Vp1Sopk2ogstE8O576NsJiw/xsGjxb//wosRURd6/w9GLoV2Q2Hp+zC6LWSOgL0bXbtvpVSNUnC4gNum38bHaz7mtha38foVr+tALUqpi6KFtTqnWmEBfHBHB+7qlkLWlhIyXshi0tx8ikvLXLvj8ETo9SKMWGr1HJI9GV5pCx/fAtkfwqHdrt2/UqpaW7prKQOnDmT13tW80O0F7mt3H95e3nbHUkpVcXrzovpdPt5ePNqjCXHHtzJ9ZxBPfpnLhJ/zebRHE65qFuf8nkPKC0+AXv+xbmj8eTTkfg4rvgTxgsRLoNE10OhaqNUUXJlDKVVtfLz6Y/7967+JD47nzavepFFkI7sjKaWqCS2sVaXVD/dmct+OzFi5i39/s5Lh7y7ikuQoHu/VlNYX2+/17wmrAz2ehWuege1LYc10WPMtzPg/a4qoB42uJfJoPJR0Ah8dLlgpdarjpcd5Zv4zfJb3GZcmXMpzlz2nTT+UUk6lhbU6LyLClc3iyGgcy4cLNvPSD2vo/9rP9GlVh4evaUzdqCDXBvDygoS21tT9MTiwDfK+swrtxe/SquQIrPwPpHS3rmQ3vBpC41ybSSnl8XYe2sn9WfeTU5jDn1r+ib+0/os2/VBKOZ0W1uqC+Hh7MaRjEv3bJPDWzHWMnb2e6ct3MLRzEvd0b0h4kK97goTVsdpgtxsGxUfIyXyNNP9tVqG9aqq1TZ220LiH1Wykdpo2GVGqhlm8czH3Z93P4ZLD/Dfjv1yVdJXdkZRS1ZQW1uqihPj78MDVjbmpQz3++90axs3ZwMcLtzDiiobc3DEJPx833h/rG8ie6HTIyABjYGcurPnGKrJ/egZ++hcERlmjP0YmQUSSNVDNifnwRPB20x8ESimXM8bw0eqPeO7X56gTUodxV48jNTLV7lhKqWpMC2vlFPHhgbxwYytuvbQ+z0xbyVNTVzDxl3weubYJPVvWdu0NjhURgdotrKnrQ1BUAGu/h01zrW77ti6yboIsKyn3Gm8IS7AK7cgkiEh2zCdbhXdILb3arao1EckHDgKlQIkxJv209QK8DPQEDgPDjDGL3Z2zMo6VHuPpeU/zxdovuCzhMp7t+ixhfmF2x1JKVXNaWCunalYnjHdvv4SZawr497RV/OWDxbStF8ETvZrSLinKvmAhsdD6Jms6obQEDm6DvflWsb1v42+Ped9D0c5T38Mn0LpJsqKr3ZFJEKA3QalqobsxpvAs63oADR1TB+ANx6NHOVJyhNun386ywmXcmXYnd7e+Gy/R3mWVUq6nhbVyOhEho3EtLmsYy6eLNvPid2u4/o259GhRm8d6NKVetItvcKwsbx+rUI6oB/UrWF98xBr18WTRnW9N+zbCpvlwbP+p2wdEnFponyy+kyG8LvgGuPxHUsrF+gGTjDEGmCciESISb4zZbnew8uZum8uywmU8delT9E/tb3ccpVQNooW1chlvL2Fg+3r0aVWHsbM28Nasdfy4ahf3Xp7Kn7o2wN/Hw+/I9w2E2MbWVJEje8+80r03H3attNp1lx47dfvQeIhIovkRgQOfQ2DkqVNQ1KnPfQNd/iMqdRoDfCciBnjLGDPmtPUJwOZyz7c4lnlUYZ1dkI2Plw896vewO4pSqobRwlq5XJCfDyOvbMgf2icy6qsV/Oe7NXy+ZCtP929B55QYu+NduBMFcJ3WZ64rK7OakpxSdFuFd9DhjbBmPRzeA2XnGCLeJ+DM4jswEvyCrfbgItZAOV7e1qN4OZY75r28Kl7uG2BdRY9OhdA61nZKWboYY7aKSC3gexFZZYyZdb5vIiLDgeEAcXFxZGVlnXeQoqKiC3odwKwds0jwSWDu7LkX9PrKupiM7uLpGT09H2hGZ/D0fOC8jFpYK7eJDw/kjSHt+Gn1Lv7xZS43jZ1P/9Z1eKJXM2JDq9mALl5eEBZvTfU6nrJqQVYWGSd6Lik+bF35PrLXKrRPzJ8x7YM9663544fBlDmm0t/my0qxLjieB58Aq5eU6BSISoHoFML3HYSDTfVmzRrIGLPV8bhLRKYAlwDlC+utQN1yzxMdy05/nzHAGID09HSTkZFx3lmyTvyenKfismIe+uAhbmh0AxmXnP/rz8eFZnQnT8/o6flAMzqDp+cD52XUwlq5XffGteh0XzSv/bSWN2euY8aqXTx8bRNuuqQe3l41qJATsa4++wVbXf05gzGO6bSC+2QhXgbHi2DPBtizDnY7pl2rYPW3UFZMG4Clj4NfKEQ3cBTcqb8V31H1rW4Jy0qtXlVOPp4+73huKljm42/d7BkQYT36h7nmynlpCRzd5/ijZc9vf8AUH7ba1kenWo/azSIiEgx4GWMOOuavBkadtlkmcI+IfIh10+J+T2tfvWbvGo6WHqVVbCu7oyilaiAtrJUtAny9eeDqxvRvk8Dfv1jO379YzqcLN/Ov61rSIkF717hgIo6rzOcoUoOirGKyQbdTl5eWwP7N5Pw0hbTEYEfRvRa2LYYVX1hFueuCQ0CYo9guV3AHRvw2f/IxnMg9KyB+Ps/kAAAd2klEQVSnwHE1f8+ZhfORPXB475k3mFbEy+e3pjEn/oA4MR8aX5Ou2scBUxxdY/oAHxhjvhWRuwCMMW8C07C62luL1d3erTZlPavsXdkApMWm2ZxEKVUTaWGtbJUSG8L7d3QgM3sbT01dSd9X53BLp2Tuv7oRYQF6FdGtvH0gqj57ottCh4xT15Uct27M3LPOejRlVkHq5W213/byKTed/tzr1OfiDSVH4eh+62ry0f3WdKTc/NETTV8cy4oPnRKnFUBOuQX+4RB0oh16lFUcB0aVuyn0xLxjvW+g1ePL7rXlpnWwfiaUHPntfX2DTi20o1NPNpkhyMbuI13AGLMex6E9bfmb5eYN8Bd35jpfOYU5xAbGEh8cb3cUpVQNpIW1sp2I0K91AhmNa/Hid6uZODefacu287fezeiTFu/+wWXUmXz8ILaRNdmhtPiUonvxwl9p2/kKq7gNiLD+KDhfobWh7iWnLisrs/o2L19s714H23NgRabVrOWEjMch45GL+7mU02XvyqZVbCs9byilbKGFtfIY4YG+jOrXghvaJfLElOWMmLyEjxds5qn+LagfE2x3PGUnb18IjrEm4EDeQdcU+V5eVnv38ERokHHqutJiq2eXE0X36UW5st3uI7vZUrSFgY0H2h1FKVVDaWGtPE5aYgRf/OVS3p+/kRe+Xc01/5vFXRkp3J2RQoCvh/d9raovb1+ISbUm5ZGyC6z21a1q6Y2LSil7aAe2yiN5ewm3dEpmxoPd6NGyNqNn5HHNS7P4YcVOrGaeSil1qhMDwzSNamp3FKVUDaWFtfJotUIDeHlQG96/owPeItwxaSH9X/+FmWsKtMBWSp0iuyCbJpFNCPAJsDuKUqqG0sJaVQmXpsYw/b6uPHd9SwoPHmPoO79y/Ru/MCevUAtspRQlZSXkFuZqMxCllK20sFZVhq+3FwPb1+OnBzP413Ut2LH/KEPens/At+Yxd91uu+MppWykA8MopTyB3ryoqhw/Hy/+2CGJG9ol8vGCzbz601oGj51HxwZRdI8pJcPugEoptzt546IW1kopG+kVa1Vl+ft4c3OnZGY+1J1/9GnGuoJD/PvXo/xx3DwWbdxjdzyllBtlF2TrwDBKKdtpYa2qvABfb269tD6zH+7O4CZ+rN5xkOvfmMst7/zKkk177Y6nlHKD7F3ZpMWm6cAwSilbubywFhFvEVkiIlMrWOcvIh+JyFoRmS8iya7Oo6qvAF9vrkn2ZdbD3XmsRxOWb93Pda//wq3jfyVnyz674ymlXOTEwDDaDEQpZTd3XLEeCaw8y7rbgb3GmFTgf8BzbsijqrkgPx/u7JbC7Ie78/C1jVmyeR99X/2ZOyYuYNmW/XbHU0o5WU5BDqDtq5VS9nNpYS0iiUAvYNxZNukHTHTMfwpcIfo9nnKSYH8f7s5IZfbD3Xnw6kb8umEPfV6dw41v/sJX2dsoLi2zO6JSygmyC7LxER+aRTezO4pSqoZzda8gLwEPA6FnWZ8AbAYwxpSIyH4gGih0cS5Vg4QG+HLP5Q25pXMyHy/YzKS5G7l38hJqhfpzU4d63HRJPWqF6YASSlVV2QXZNInSgWGUUvZzWWEtIr2BXcaYRSKScZHvNRwYDhAXF0dWVtZ5v0dRUdEFvc6dPD2jp+eD38+YCvyzPSwr9GfGxhJe+iGPV2bkkR7nzZVJvqRGeLn85idPP46eng80o/pNSVkJubtzGdBwgN1RlFLKpVesLwX6ikhPIAAIE5H3jDFDym2zFagLbBERHyAcOGOkD2PMGGAMQHp6usnIyDjvMFlZWVzI69zJ0zN6ej6ofMbLsRr/byg8xHvzNvLxws3M33GUZvFhDO2cRN9WCQT6edua0S6eng80o/rNmr1rOFJyhLSYNLujKKWU69pYG2MeM8YkGmOSgUHAj6cV1QCZwFDH/A2ObXR8auU29WOC+XvvZsx//Aqeua4lZcbwyGfL6PjvGTwzbSWbdh+2O6JS6hxO3rioQ5krpTyA20deFJFRwEJjTCbwNvCuiKwF9mAV4Eq5XZCfDzd1qMfgS+ry64Y9TJq7kbfnbGDs7PVc3rgWt3RO5rLUGLy89N5apTxJdkE2MYEx1AmuY3cUpZRyT2FtjMkCshzzT5ZbfhS40R0ZlKoMEaFDg2g6NIhmx/6jfDB/Ix/8uomh7/xKcnQQN3dK5sb0RMICfO2OqpTCKqxbxbbSgWGUUh5BR15U6ixqhwdw/9WN+fnRy3l5UGuigv14auoKOv/7R56auoLNe7SZiFJ22n1kN5sPbtb+q5VSHsPtTUGUqmr8fbzp1zqBfq0TyNmyj7fnbGDiL/mM/3kD17aoze1d6tO2XqReMVPKzXRgGKWUp9HCWqnzkJYYwcuD2vBojyZM/GUjH8zfyLRlO2hdN4Lbu9SnR4va+HjrF0FKuYMODKOU8jRaASh1AeLDA3m0RxPmPnYFo/o1Z9/h49w7eQndXshizKx17D9SbHdEpaq9nMIcGkc11oFhlFIeQwtrpS5CsL8Pt3RK5scHMhh7Szp1owJ5ZtoqOv97Bv/MzNXu+pRykZKyEpYXLtdmIEopj6JNQZRyAi8v4apmcVzVLI7lW/fzzpwNvDdvIxPn5nN1szjuuKwB6UnaDlspZ8nbm8eRkiNaWCulPIoW1ko5WYuEcP47sDWP9GjCpLn5vD9/E9Nzd5KWGM7tXeoTXKZjICl1sbILsgEdGEYp5Vm0sFbKReLCAnjomibc070hny3ewjtzNjDyw6WE+cHgYysZmF6XBrEhdsdUqkrKLsgmOiBaB4ZRSnkUbWOtlIsF+nkzpGMSP9zfjfHD2pMa4c242Ru4/MWZDHxrLlOWbOFocandMVUNJyJ1ReQnEVkhIrkiMrKCbTJEZL+ILHVMT1b0Xu6QU5CjA8MopTyOXrFWyk28vITuTWohOwJo1rYjny7ewkcLNnPfR9k8+WUu17VJYGD7ujSvE253VFUzlQAPGGMWi0gosEhEvjfGrDhtu9nGmN425Dtpz9E9bDq4iesbXW9nDKWUOoMW1krZoFZYAHdnpHJX1xTmb9jDhws28eGCzUyau5G0xHAGtq9L31Z1CNWh05WbGGO2A9sd8wdFZCWQAJxeWNtOB4ZRSnkqLayVspGXl9ApJZpOKdH83+HjfLFkKx8u2MwTU5bz9NSV9EqLZ1D7urTTHkWUG4lIMtAGmF/B6k4ikg1sAx40xuS6MRrw28AwzaObu3vXSil1TlpYK+UhIoL8GHZpfYZ2TiZ7y34+WrCJzKXb+HTRFlJrhTCofV2ua5NAdIi/3VFVNSYiIcBnwF+NMQdOW70YSDLGFIlIT+ALoGEF7zEcGA4QFxdHVlbWeecoKio66+tm7phJHd86zJsz77zf15nOldFTeHpGT88HmtEZPD0fOC+jFtZKeRgRoXXdCFrXjeBvvZoxNWcbHy7YzNNfr+S5b1fRs2U8f85IoUntMLujqmpGRHyxiur3jTGfn76+fKFtjJkmIq+LSIwxpvC07cYAYwDS09NNRkbGeWfJysqioteVlJXw8OSH6Z/an4wO5/++znS2jJ7E0zN6ej7QjM7g6fnAeRm1sFbKgwX7+zCwfT0Gtq/H6h0H+XDBJj5esJkvl27jyqZx3HN5Kq3rRtgdU1UDYrU1ehtYaYz571m2qQ3sNMYYEbkEq2ep3W6Mydp9a3VgGKWUx9LCWqkqonHtUP7Rpzkjr2jIhF/yGf9zPv1f+5kuqTHc3T2FTg2itR22uhiXAjcDy0RkqWPZ40A9AGPMm8ANwJ9FpAQ4Agwyxrh1xKPsXY6BYbSwVkp5IC2slapiIoL8+OuVjbjjsga8P28jY2dv4Kax82lbL4J7Lk+le+NaWmCr82aMmQOc84NjjHkVeNU9iSp2YmCYhJAEO2MopVSFdIAYpaqoEH8f7uyWwpxHujOqX3N2HjjGbRMW0mv0HL7O2U6pDp2uqqHsgmwdGEYp5bG0sFaqigvw9eaWTslkPZTBCzekcbS4lL98sJir/jeTTxdtobi0zO6ISjnFiYFhWtXSZiBKKc+khbVS1YSvtxc3ptfl+/u78epNbfD38ebBT7LJeCGLd+fm67Dpqso7MTBMWkyazUmUUqpiWlgrVc14ewm90+owbUQX3h6aTq0wf/7+ZS6XPf8TY2at49CxErsjKnVBcgpyrIFhYnRgGKWUZ9KbF5WqpkSEK5rGcXmTWsxdv5vXflrLM9NW8cqMtXROjaZLw1i6NowhKTrY7qhKVUp2QTaNohoR6BNodxSllKqQFtZKVXMiQueUGDqnxLB4014+XrCZ2XmFTM/dCUDdqEC6pFpFdueUGJvTKlWxkrISlhUuo39qf7ujKKXUWWlhrVQN0rZeJG3rRWKMYUPhIeasLWR2XiFfZW9j8q+b8BJIDvNi0fHVdEmNoU29SPx8tMWYsp8ODKOUqgq0sFaqBhIRGsSG0CA2hFs6JVNcWkb25n3Myitk2qJ1vJ61jld+XEuwnzcdG0TTpWEMlzWMJSU2WLs5U7Y4MTBMWqzeuKiU8lxaWCul8PX2Ij05ivTkKNr6bqNNh0uZu243c9YWMCevkBmrdgEQHx5Al9QYerSszWUNY/H11qvZyj1yCnOICogiMSTR7ihKKXVWWlgrpc4QHujLtS1qc22L2gBs3nOY2XmFzFlbwPTcHXyyaAuRQb70Sounf+sE2iVF6pVs5VI6MIxSqirQwlop9bvqRgVxU4d63NShHsdLypi1poAvlm7l00VbeG/eJhIjA+nbqg792yTQKC7U7riqmtl7dC8bD2zkutTr7I6ilFLnpIW1Uuq8+Pl4cWWzOK5sFkfRsRK+y93Bl0u38das9byetY4mtUPp3yaBPq3qkBCh3aKpi3diYBi9cVEp5em0sFZKXbAQfx8GtE1kQNtECg4eY9qy7XyxdCvPfrOKZ79ZxSX1o+jXug69WsYTEeRnd1xVRWUXZOMt3jowjFLK42lhrZRyithQf4Z2TmZo52Q27T7Ml0u38sXSrTwxZTn/zMylW6NY+rVO4MqmcQT6edsdV1Uh2QXZNIrUgWGUUp5PC2ullNPViw7i3isacs/lqeRuO0Bm9jYyl27jh5W7CPbzJqNJLbo1iqVbo1jiwgLsjqs8WGlZKcsKl9EvpZ/dUZRS6ndpYa2UchkRoUVCOC0Swnnk2ib8umEPmdlbmbFyF1/nbAegSe3Qk0V2u+RI/H30arb6zcmBYWpp+2qllOfTwlop5RbeXkKnlGg6pURjjGHVjoPMWlPAzDUFvPPzBt6atZ4gP286p0TTrVEsXRvFkhQdbHdsZbPsAmtgGL1xUSlVFWhhrZRyOxGhaXwYTePDuLNbCoeOlTB33W5mOgrtH1ZaA9IkRwdZV7Mbx9KxQTRBfnrKqmmyC7J1YBilVJWh/0sppWwX7O9zsgs/gPzCQyeL7I8XbmHi3I34eXvRvn4k3RrFElxUZnNi5S7ZBdmkxabpwDBKqSpBC2ullMdJjgkmOSaYoZ2TOVZSysL8vVahvbqAZ6atAmD8mpn0bBlPz5a1aRwXqoVXNXRiYJj+qf3tjqKUUpXissJaRAKAWYC/Yz+fGmP+cdo2w4AXgK2ORa8aY8a5KpNSqurx9/Hm0tQYLk2N4fGeTdm+/wivfzmHvKN+vPpjHqNn5NEgNpieLeLp2TKepvFaZFcXywqXAdq+WilVdbjyivUx4HJjTJGI+AJzROQbY8y807b7yBhzjwtzKKWqkfjwQK6o58tTGZ0oOHiM6bk7+Gb5dl7PWsurP62lfkwwPVrUpmfLeJrXCdMiuwpbumupNTBMtA4Mo5SqGlxWWBtjDFDkeOrrmIyr9qeUqnliQ/0Z0jGJIR2T2F10jOm5O/lm+faTw6snRQfRo0U8vVrG0yJBi+yqJqcgh0aRjQjyDbI7ilJKVYpL21iLiDewCEgFXjPGzK9gs+tFpCuwBrjPGLPZlZmUUtVTdIg/N3Wox00d6rHn0HG+y93BtOU7GDd7PW/OXEfdqMCTzUXSEsO1yPZwZaaMZYXL6JvS1+4oSilVaS4trI0xpUBrEYkApohIC2PM8nKbfAVMNsYcE5E7gYnA5ae/j4gMB4YDxMXFkZWVdd5ZioqKLuh17uTpGT09H2hGZ/D0fFC5jLWB2xrAHxIDWbyrhIU7jjNu9nremrWe6ADhkngfOtT2JinMyyVFdlU4jp5sW/E2DpccJi02ze4oSilVaW7pFcQYs09EfgKuBZaXW7673GbjgOfP8voxwBiA9PR0k5GRcd4ZsrKyuJDXuZOnZ/T0fKAZncHT88H5Z+zteNx/uJjvV+7k65xtfJ9XyDcbikmODqJ3Wjy9W8U7tXeRqnAcPVn+sXwAWse2tjeIUkqdB1f2ChILFDuK6kDgKuC507aJN8ZsdzztC6x0VR6llAoP8uWGdonc0C6RfYePMz13B19l/3bjY2qtEKvITqtDaq0Qu+PWaBuObbAGhgnVgWGUUlWHK69YxwMTHe2svYCPjTFTRWQUsNAYkwmMEJG+QAmwBxjmwjxKKXVSRJAfA9vXY2D7ehQWHeOb5TuYmr2Nl2fk8dIPeTSND6N3Wjx90upQL7pm3DwnItcCLwPewDhjzLOnrfcHJgHtgN3AQGNMviuy5B/LJy1eB4ZRSlUtruwVJAdoU8HyJ8vNPwY85qoMSilVGTEh/tzcMYmbOyax88BRvs7ZztScbbwwfTUvTF9NWmI4fdLq0CstnjoRgXbHdQnHRZDXsL5d3AIsEJFMY8yKcpvdDuw1xqSKyCCsbyEHOjvLvqP72FWyi8Gxg5391kop5VI68qJSSpUTFxbAbV3qc1uX+mzZe9hRZG/nX9NW8q9pK2mXFEnvNKsLv1phAXbHdaZLgLXGmPUAIvIh0A8oX1j3A/7pmP8UeFVExNG9qtPkFOYAOjCMUqrq0cJaKaXOIjEyiDu7pXBntxTyCw8xNWcbU3O2839frWDf4WLuu6qR3RGdKQEo393pFqDD2bYxxpSIyH4gGigsv9HF9uQ0de9UvPBiz4o9ZK06v9e6U1Xo+cXTM3p6PtCMzuDp+cB5GbWwVkqpSkiOCeaeyxtyz+UNydt5kLBAX7sjeayL7ckp/Xg6zX9qzjWXX+OCdM5TFXp+8fSMnp4PNKMzeHo+cF5GLayVUuo8NYwLtTuCK2wF6pZ7nuhYVtE2W0TEBwjHuonRqUL8QqjvX9/Zb6uUUi7nZXcApZRSHmEB0FBE6ouIHzAIyDxtm0xgqGP+BuBHZ7evVkqpqkyvWCullDrRZvoeYDpWd3vvGGNyT+si9W3gXRFZi9VF6iD7EiullOfRwloppRQAxphpwLTTlpXvIvUocKO7cymlVFWhTUGUUkoppZRyAi2slVJKKaWUcgItrJVSSimllHICLayVUkoppZRyAi2slVJKKaWUcgItrJVSSimllHICLayVUkoppZRyAqlqg2aJSAGw8QJeGgMUOjmOs3l6Rk/PB5rRGTw9H1TtjEnGmFh3h7GLnrNt5+kZPT0faEZn8PR84KRzdpUrrC+UiCw0xqTbneNcPD2jp+cDzegMnp4PNGNNUBWOn2a8eJ6eDzSjM3h6PnBeRm0KopRSSimllBNoYa2UUkoppZQT1KTCeozdASrB0zN6ej7QjM7g6flAM9YEVeH4acaL5+n5QDM6g6fnAydlrDFtrJVSSimllHKlmnTFWimllFJKKZepdoW1iFwrIqtFZK2IPFrBen8R+cixfr6IJLsxW10R+UlEVohIroiMrGCbDBHZLyJLHdOT7spXLkO+iCxz7H9hBetFREY7jmGOiLR1c77G5Y7PUhE5ICJ/PW0btx9HEXlHRHaJyPJyy6JE5HsRyXM8Rp7ltUMd2+SJyFA35ntBRFY5/h2niEjEWV57zs+EizP+U0S2lvu37HmW157zd9/FGT8qly9fRJae5bVuOY5ViSefsx371/P2xWfTc7ZzM3rMeVvP2RUwxlSbCfAG1gENAD8gG2h22jZ3A2865gcBH7kxXzzQ1jEfCqypIF8GMNXm45gPxJxjfU/gG0CAjsB8m//Nd2D1M2nrcQS6Am2B5eWWPQ886ph/FHiugtdFAesdj5GO+Ug35bsa8HHMP1dRvsp8Jlyc8Z/Ag5X4HJzzd9+VGU9b/yLwpJ3HsapMnn7OduxTz9vO/zfXc/bFZfSY87aes8+cqtsV60uAtcaY9caY48CHQL/TtukHTHTMfwpcISLijnDGmO3GmMWO+YPASiDBHft2sn7AJGOZB0SISLxNWa4A1hljLmQACqcyxswC9py2uPznbSLQv4KXXgN8b4zZY4zZC3wPXOuOfMaY74wxJY6n84BEZ+/3fJzlGFZGZX73neJcGR3nkj8Ak12x72rIo8/ZoOdtF9Bz9kVm9KTztp6zz1TdCusEYHO551s48wR4chvHB3M/EO2WdOU4vs5sA8yvYHUnEckWkW9EpLlbg1kM8J2ILBKR4RWsr8xxdpdBnP0Xwu7jCBBnjNnumN8BxFWwjaccz9uwrmhV5Pc+E652j+Nrz3fO8tWspxzDy4Cdxpi8s6y3+zh6mipzzgY9bzuJnrOdy1PP2zX2nF3dCusqQURCgM+AvxpjDpy2ejHWV2StgFeAL9ydD+hijGkL9AD+IiJdbcjwu0TED+gLfFLBak84jqcw1vdKHtkNj4g8AZQA759lEzs/E28AKUBrYDvW13aeajDnvvJRJX631Jn0vH3x9JztXB583q7R5+zqVlhvBeqWe57oWFbhNiLiA4QDu92SztqnL9bJ+X1jzOenrzfGHDDGFDnmpwG+IhLjrnyO/W51PO4CpmB9ZVNeZY6zO/QAFhtjdp6+whOOo8POE1+3Oh53VbCNrcdTRIYBvYE/Ov4jOUMlPhMuY4zZaYwpNcaUAWPPsm/bP5OO88kA4KOzbWPncfRQHn/OduxXz9vOoedsJ/Hk83ZNP2dXt8J6AdBQROo7/jIeBGSetk0mcOIO3huAH8/2oXQ2R1uet4GVxpj/nmWb2ifaD4rIJVj/Ru4s/INFJPTEPNZNEstP2ywTuEUsHYH95b46c6ez/qVp93Esp/znbSjwZQXbTAeuFpFIx1dmVzuWuZyIXAs8DPQ1xhw+yzaV+Uy4MmP5dqDXnWXflfndd7UrgVXGmC0VrbT7OHoojz5ng563nUzP2U7g6eftGn/OruxdjlVlwrrzeQ3W3aZPOJaNwvoAAgRgfQ21FvgVaODGbF2wvlbKAZY6pp7AXcBdjm3uAXKx7pCdB3R28/Fr4Nh3tiPHiWNYPqMArzmO8TIg3YZ/52Csk254uWW2Hkes/zC2A8VY7cVux2oLOgPIA34AohzbpgPjyr32Nsdnci1wqxvzrcVq53bi83ii94U6wLRzfSbcmPFdx+csB+vEG396RsfzM3733ZXRsXzCic9fuW1tOY5Vaaro3w0POWc79q/nbedk1HO28zJ6zHn7LPlq9DlbR15USimllFLKCapbUxCllFJKKaVsoYW1UkoppZRSTqCFtVJKKaWUUk6ghbVSSimllFJOoIW1UkoppZRSTqCFtaqWRKRURJaWmx514nsni0hN739YKaWcRs/ZqrrwsTuAUi5yxBjT2u4QSimlKkXP2apa0CvWqkYRkXwReV5ElonIryKS6lieLCI/ikiOiMwQkXqO5XEiMkVEsh1TZ8dbeYvIWBHJFZHvRCTQth9KKaWqKT1nq6pGC2tVXQWe9rXiwHLr9htjWgKvAi85lr0CTDTGpAHvA6Mdy0cDM40xrYC2WKMvATQEXjPGNAf2Ade7+OdRSqnqTM/ZqlrQkRdVtSQiRcaYkAqW5wOXG2PWi4gvsMMYEy0ihVjDrhY7lm83xsSISAGQaIw5Vu49koHvjTENHc8fAXyNMU+7/idTSqnqR8/ZqrrQK9aqJjJnmT8fx8rNl6L3KyillKvoOVtVGVpYq5poYLnHuY75X4BBjvk/ArMd8zOAPwOIiLeIhLsrpFJKKUDP2aoK0b/YVHUVKCJLyz3/1hhzovumSBHJwbqCMdix7F5gvIg8BBQAtzqWjwTGiMjtWFc5/gxsd3l6pZSqWfScraoFbWOtahRHe710Y0yh3VmUUkqdm56zVVWjTUGUUkoppZRyAr1irZRSSimllBPoFWullFJKKaWcQAtrpZRSSimlnEALa6WUUkoppZxAC2ullFJKKaWcQAtrpZRSSimlnEALa6WUUkoppZzg/wEORGrncUd/3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].plot(history['loss'], label='train')\n",
    "axes[0].plot(history['val_loss'], label='valid')\n",
    "axes[0].set_title('Loss history')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "axes[1].plot(history['acc'], label='train')\n",
    "axes[1].plot(history['val_acc'], label='valid')\n",
    "axes[1].plot(np.array(history['bleu4']) * 100., label='BLEU-4')\n",
    "axes[1].set_title('Accuracy history')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation - BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Inference - Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
